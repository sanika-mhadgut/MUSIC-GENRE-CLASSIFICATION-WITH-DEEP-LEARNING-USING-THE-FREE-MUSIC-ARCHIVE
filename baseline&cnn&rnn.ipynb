{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification Using Deep Learning\n",
    "Data source: [FMA: A Dataset For Music Analysis](https://github.com/mdeff/fma)\n",
    "\n",
    "Yetong Chen\n",
    "\n",
    "* This notebook evaluates standard classifiers from scikit-learn on the provided features.\n",
    "* Moreover, it evaluates Deep Learning models on the provided features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install python-dotenv pydot requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "# import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, LabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AUDIO_DIR'] = 'D:\\\\code\\\\BIA667\\\\fma\\\\data\\\\fma_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106574, 52), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "\n",
    "tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "features = utils.load('data/fma_metadata/features.csv')\n",
    "echonest = utils.load('data/fma_metadata/echonest.csv')\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\code\\BIA667\\fma\\data\\fma_small\n"
     ]
    }
   ],
   "source": [
    "print(AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)  # Python random module\n",
    "    np.random.seed(seed_value)  # Numpy module\n",
    "    torch.manual_seed(seed_value)  # PyTorch random number generator for CPU\n",
    "    \n",
    "    # if using CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  # if using multi-GPU\n",
    "\n",
    "# Use a known seed to initialize random number generator for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (13129, 767)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((25000, 52), (25000, 518))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = tracks.index[tracks['set', 'subset'] <= 'medium']\n",
    "\n",
    "assert subset.isin(tracks.index).all()\n",
    "assert subset.isin(features.index).all()\n",
    "\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "\n",
    "tracks = tracks.loc[subset]\n",
    "features_all = features.loc[subset]\n",
    "\n",
    "tracks.shape, features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2505 validation examples, 2573 testing examples\n",
      "Top genres (16): ['Blues', 'Classical', 'Country', 'Easy Listening', 'Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Jazz', 'Old-Time / Historic', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']\n",
      "All genres (151): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 53, 58, 63, 64, 65, 66, 70, 71, 74, 76, 77, 79, 81, 83, 85, 86, 88, 89, 90, 92, 94, 97, 98, 100, 101, 102, 103, 107, 109, 111, 113, 117, 118, 125, 130, 137, 138, 166, 167, 169, 171, 172, 174, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 214, 224, 232, 236, 240, 247, 250, 267, 286, 296, 297, 311, 314, 322, 337, 359, 360, 361, 362, 374, 378, 400, 401, 404, 428, 439, 440, 441, 442, 443, 456, 468, 491, 495, 502, 504, 514, 524, 538, 539, 542, 580, 602, 619, 651, 659, 695, 741, 763, 808, 810, 811, 906, 1032, 1060, 1193, 1235]\n"
     ]
    }
   ],
   "source": [
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n",
    "\n",
    "genres = list(LabelEncoder().fit(tracks['track', 'genre_top']).classes_)\n",
    "#genres = list(tracks['track', 'genre_top'].unique())\n",
    "print('Top genres ({}): {}'.format(len(genres), genres))\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print('All genres ({}): {}'.format(len(genres), genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "        #y = enc.fit_transform(tracks['track', 'genre_top'])\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "        #labels = tracks['track', 'genres']\n",
    "\n",
    "    # Split in training, validation and testing sets.\n",
    "    y_train = enc.fit_transform(labels[train])\n",
    "    y_val = enc.transform(labels[val])\n",
    "    y_test = enc.transform(labels[test])\n",
    "    X_train = features.loc[train, columns].to_numpy()\n",
    "    X_val = features.loc[val, columns].to_numpy()\n",
    "    X_test = features.loc[test, columns].to_numpy()\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "    scaler.transform(X_test)\n",
    "\n",
    "    # print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "    # print(f'X_val shape: {X_val.shape}, y_val shape: {y_val.shape}')\n",
    "    # print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
    "\n",
    "\n",
    "    return y_train, y_val, y_test, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Single genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    columns = list(classifiers.keys()).insert(0, 'dim')\n",
    "    scores = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    times = pd.DataFrame(columns=classifiers.keys(), index=feature_sets.keys())\n",
    "    for fset_name, fset in tqdm(feature_sets.items(), desc='features'):\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        scores.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            scores.loc[fset_name, clf_name] = score\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "    return scores, times\n",
    "\n",
    "def format_scores(scores):\n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfefe89da4b4a019162141874f4e588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "features:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_53c9e_row0_col3, #T_53c9e_row1_col3, #T_53c9e_row2_col3, #T_53c9e_row3_col3, #T_53c9e_row4_col3, #T_53c9e_row5_col10, #T_53c9e_row6_col10, #T_53c9e_row7_col3, #T_53c9e_row8_col10, #T_53c9e_row9_col3, #T_53c9e_row10_col10, #T_53c9e_row11_col3, #T_53c9e_row12_col3, #T_53c9e_row13_col3, #T_53c9e_row14_col3, #T_53c9e_row15_col3, #T_53c9e_row16_col3, #T_53c9e_row17_col3 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_53c9e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_53c9e_level0_col0\" class=\"col_heading level0 col0\" >dim</th>\n",
       "      <th id=\"T_53c9e_level0_col1\" class=\"col_heading level0 col1\" >LR</th>\n",
       "      <th id=\"T_53c9e_level0_col2\" class=\"col_heading level0 col2\" >kNN</th>\n",
       "      <th id=\"T_53c9e_level0_col3\" class=\"col_heading level0 col3\" >SVCrbf</th>\n",
       "      <th id=\"T_53c9e_level0_col4\" class=\"col_heading level0 col4\" >SVCpoly1</th>\n",
       "      <th id=\"T_53c9e_level0_col5\" class=\"col_heading level0 col5\" >linSVC1</th>\n",
       "      <th id=\"T_53c9e_level0_col6\" class=\"col_heading level0 col6\" >linSVC2</th>\n",
       "      <th id=\"T_53c9e_level0_col7\" class=\"col_heading level0 col7\" >DT</th>\n",
       "      <th id=\"T_53c9e_level0_col8\" class=\"col_heading level0 col8\" >RF</th>\n",
       "      <th id=\"T_53c9e_level0_col9\" class=\"col_heading level0 col9\" >AdaBoost</th>\n",
       "      <th id=\"T_53c9e_level0_col10\" class=\"col_heading level0 col10\" >MLP1</th>\n",
       "      <th id=\"T_53c9e_level0_col11\" class=\"col_heading level0 col11\" >MLP2</th>\n",
       "      <th id=\"T_53c9e_level0_col12\" class=\"col_heading level0 col12\" >NB</th>\n",
       "      <th id=\"T_53c9e_level0_col13\" class=\"col_heading level0 col13\" >QDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "      <td id=\"T_53c9e_row0_col0\" class=\"data row0 col0\" >84.000000</td>\n",
       "      <td id=\"T_53c9e_row0_col1\" class=\"data row0 col1\" >39.45%</td>\n",
       "      <td id=\"T_53c9e_row0_col2\" class=\"data row0 col2\" >37.50%</td>\n",
       "      <td id=\"T_53c9e_row0_col3\" class=\"data row0 col3\" >42.29%</td>\n",
       "      <td id=\"T_53c9e_row0_col4\" class=\"data row0 col4\" >38.63%</td>\n",
       "      <td id=\"T_53c9e_row0_col5\" class=\"data row0 col5\" >39.29%</td>\n",
       "      <td id=\"T_53c9e_row0_col6\" class=\"data row0 col6\" >39.18%</td>\n",
       "      <td id=\"T_53c9e_row0_col7\" class=\"data row0 col7\" >35.68%</td>\n",
       "      <td id=\"T_53c9e_row0_col8\" class=\"data row0 col8\" >33.42%</td>\n",
       "      <td id=\"T_53c9e_row0_col9\" class=\"data row0 col9\" >30.86%</td>\n",
       "      <td id=\"T_53c9e_row0_col10\" class=\"data row0 col10\" >38.98%</td>\n",
       "      <td id=\"T_53c9e_row0_col11\" class=\"data row0 col11\" >33.46%</td>\n",
       "      <td id=\"T_53c9e_row0_col12\" class=\"data row0 col12\" >9.99%</td>\n",
       "      <td id=\"T_53c9e_row0_col13\" class=\"data row0 col13\" >24.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row1\" class=\"row_heading level0 row1\" >chroma_cqt</th>\n",
       "      <td id=\"T_53c9e_row1_col0\" class=\"data row1 col0\" >84.000000</td>\n",
       "      <td id=\"T_53c9e_row1_col1\" class=\"data row1 col1\" >40.19%</td>\n",
       "      <td id=\"T_53c9e_row1_col2\" class=\"data row1 col2\" >40.03%</td>\n",
       "      <td id=\"T_53c9e_row1_col3\" class=\"data row1 col3\" >44.27%</td>\n",
       "      <td id=\"T_53c9e_row1_col4\" class=\"data row1 col4\" >39.95%</td>\n",
       "      <td id=\"T_53c9e_row1_col5\" class=\"data row1 col5\" >41.39%</td>\n",
       "      <td id=\"T_53c9e_row1_col6\" class=\"data row1 col6\" >40.61%</td>\n",
       "      <td id=\"T_53c9e_row1_col7\" class=\"data row1 col7\" >35.45%</td>\n",
       "      <td id=\"T_53c9e_row1_col8\" class=\"data row1 col8\" >35.72%</td>\n",
       "      <td id=\"T_53c9e_row1_col9\" class=\"data row1 col9\" >35.72%</td>\n",
       "      <td id=\"T_53c9e_row1_col10\" class=\"data row1 col10\" >42.09%</td>\n",
       "      <td id=\"T_53c9e_row1_col11\" class=\"data row1 col11\" >36.92%</td>\n",
       "      <td id=\"T_53c9e_row1_col12\" class=\"data row1 col12\" >1.55%</td>\n",
       "      <td id=\"T_53c9e_row1_col13\" class=\"data row1 col13\" >3.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row2\" class=\"row_heading level0 row2\" >chroma_stft</th>\n",
       "      <td id=\"T_53c9e_row2_col0\" class=\"data row2 col0\" >84.000000</td>\n",
       "      <td id=\"T_53c9e_row2_col1\" class=\"data row2 col1\" >43.72%</td>\n",
       "      <td id=\"T_53c9e_row2_col2\" class=\"data row2 col2\" >43.92%</td>\n",
       "      <td id=\"T_53c9e_row2_col3\" class=\"data row2 col3\" >48.31%</td>\n",
       "      <td id=\"T_53c9e_row2_col4\" class=\"data row2 col4\" >43.65%</td>\n",
       "      <td id=\"T_53c9e_row2_col5\" class=\"data row2 col5\" >44.35%</td>\n",
       "      <td id=\"T_53c9e_row2_col6\" class=\"data row2 col6\" >43.30%</td>\n",
       "      <td id=\"T_53c9e_row2_col7\" class=\"data row2 col7\" >39.88%</td>\n",
       "      <td id=\"T_53c9e_row2_col8\" class=\"data row2 col8\" >40.03%</td>\n",
       "      <td id=\"T_53c9e_row2_col9\" class=\"data row2 col9\" >35.25%</td>\n",
       "      <td id=\"T_53c9e_row2_col10\" class=\"data row2 col10\" >46.95%</td>\n",
       "      <td id=\"T_53c9e_row2_col11\" class=\"data row2 col11\" >41.16%</td>\n",
       "      <td id=\"T_53c9e_row2_col12\" class=\"data row2 col12\" >4.20%</td>\n",
       "      <td id=\"T_53c9e_row2_col13\" class=\"data row2 col13\" >5.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row3\" class=\"row_heading level0 row3\" >mfcc</th>\n",
       "      <td id=\"T_53c9e_row3_col0\" class=\"data row3 col0\" >140.000000</td>\n",
       "      <td id=\"T_53c9e_row3_col1\" class=\"data row3 col1\" >58.03%</td>\n",
       "      <td id=\"T_53c9e_row3_col2\" class=\"data row3 col2\" >54.99%</td>\n",
       "      <td id=\"T_53c9e_row3_col3\" class=\"data row3 col3\" >60.98%</td>\n",
       "      <td id=\"T_53c9e_row3_col4\" class=\"data row3 col4\" >59.66%</td>\n",
       "      <td id=\"T_53c9e_row3_col5\" class=\"data row3 col5\" >59.19%</td>\n",
       "      <td id=\"T_53c9e_row3_col6\" class=\"data row3 col6\" >57.21%</td>\n",
       "      <td id=\"T_53c9e_row3_col7\" class=\"data row3 col7\" >45.82%</td>\n",
       "      <td id=\"T_53c9e_row3_col8\" class=\"data row3 col8\" >45.12%</td>\n",
       "      <td id=\"T_53c9e_row3_col9\" class=\"data row3 col9\" >41.31%</td>\n",
       "      <td id=\"T_53c9e_row3_col10\" class=\"data row3 col10\" >50.45%</td>\n",
       "      <td id=\"T_53c9e_row3_col11\" class=\"data row3 col11\" >52.47%</td>\n",
       "      <td id=\"T_53c9e_row3_col12\" class=\"data row3 col12\" >41.86%</td>\n",
       "      <td id=\"T_53c9e_row3_col13\" class=\"data row3 col13\" >48.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row4\" class=\"row_heading level0 row4\" >rmse</th>\n",
       "      <td id=\"T_53c9e_row4_col0\" class=\"data row4 col0\" >7.000000</td>\n",
       "      <td id=\"T_53c9e_row4_col1\" class=\"data row4 col1\" >36.92%</td>\n",
       "      <td id=\"T_53c9e_row4_col2\" class=\"data row4 col2\" >38.52%</td>\n",
       "      <td id=\"T_53c9e_row4_col3\" class=\"data row4 col3\" >38.90%</td>\n",
       "      <td id=\"T_53c9e_row4_col4\" class=\"data row4 col4\" >37.70%</td>\n",
       "      <td id=\"T_53c9e_row4_col5\" class=\"data row4 col5\" >37.58%</td>\n",
       "      <td id=\"T_53c9e_row4_col6\" class=\"data row4 col6\" >37.35%</td>\n",
       "      <td id=\"T_53c9e_row4_col7\" class=\"data row4 col7\" >38.63%</td>\n",
       "      <td id=\"T_53c9e_row4_col8\" class=\"data row4 col8\" >37.19%</td>\n",
       "      <td id=\"T_53c9e_row4_col9\" class=\"data row4 col9\" >34.67%</td>\n",
       "      <td id=\"T_53c9e_row4_col10\" class=\"data row4 col10\" >38.55%</td>\n",
       "      <td id=\"T_53c9e_row4_col11\" class=\"data row4 col11\" >38.83%</td>\n",
       "      <td id=\"T_53c9e_row4_col12\" class=\"data row4 col12\" >11.78%</td>\n",
       "      <td id=\"T_53c9e_row4_col13\" class=\"data row4 col13\" >15.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row5\" class=\"row_heading level0 row5\" >spectral_bandwidth</th>\n",
       "      <td id=\"T_53c9e_row5_col0\" class=\"data row5 col0\" >7.000000</td>\n",
       "      <td id=\"T_53c9e_row5_col1\" class=\"data row5 col1\" >40.58%</td>\n",
       "      <td id=\"T_53c9e_row5_col2\" class=\"data row5 col2\" >45.39%</td>\n",
       "      <td id=\"T_53c9e_row5_col3\" class=\"data row5 col3\" >44.46%</td>\n",
       "      <td id=\"T_53c9e_row5_col4\" class=\"data row5 col4\" >40.38%</td>\n",
       "      <td id=\"T_53c9e_row5_col5\" class=\"data row5 col5\" >40.46%</td>\n",
       "      <td id=\"T_53c9e_row5_col6\" class=\"data row5 col6\" >40.50%</td>\n",
       "      <td id=\"T_53c9e_row5_col7\" class=\"data row5 col7\" >42.91%</td>\n",
       "      <td id=\"T_53c9e_row5_col8\" class=\"data row5 col8\" >44.07%</td>\n",
       "      <td id=\"T_53c9e_row5_col9\" class=\"data row5 col9\" >37.47%</td>\n",
       "      <td id=\"T_53c9e_row5_col10\" class=\"data row5 col10\" >45.51%</td>\n",
       "      <td id=\"T_53c9e_row5_col11\" class=\"data row5 col11\" >43.57%</td>\n",
       "      <td id=\"T_53c9e_row5_col12\" class=\"data row5 col12\" >36.18%</td>\n",
       "      <td id=\"T_53c9e_row5_col13\" class=\"data row5 col13\" >34.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row6\" class=\"row_heading level0 row6\" >spectral_centroid</th>\n",
       "      <td id=\"T_53c9e_row6_col0\" class=\"data row6 col0\" >7.000000</td>\n",
       "      <td id=\"T_53c9e_row6_col1\" class=\"data row6 col1\" >42.75%</td>\n",
       "      <td id=\"T_53c9e_row6_col2\" class=\"data row6 col2\" >45.36%</td>\n",
       "      <td id=\"T_53c9e_row6_col3\" class=\"data row6 col3\" >45.71%</td>\n",
       "      <td id=\"T_53c9e_row6_col4\" class=\"data row6 col4\" >42.09%</td>\n",
       "      <td id=\"T_53c9e_row6_col5\" class=\"data row6 col5\" >42.09%</td>\n",
       "      <td id=\"T_53c9e_row6_col6\" class=\"data row6 col6\" >42.17%</td>\n",
       "      <td id=\"T_53c9e_row6_col7\" class=\"data row6 col7\" >42.67%</td>\n",
       "      <td id=\"T_53c9e_row6_col8\" class=\"data row6 col8\" >43.88%</td>\n",
       "      <td id=\"T_53c9e_row6_col9\" class=\"data row6 col9\" >42.60%</td>\n",
       "      <td id=\"T_53c9e_row6_col10\" class=\"data row6 col10\" >47.30%</td>\n",
       "      <td id=\"T_53c9e_row6_col11\" class=\"data row6 col11\" >45.94%</td>\n",
       "      <td id=\"T_53c9e_row6_col12\" class=\"data row6 col12\" >33.31%</td>\n",
       "      <td id=\"T_53c9e_row6_col13\" class=\"data row6 col13\" >36.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row7\" class=\"row_heading level0 row7\" >spectral_contrast</th>\n",
       "      <td id=\"T_53c9e_row7_col0\" class=\"data row7 col0\" >49.000000</td>\n",
       "      <td id=\"T_53c9e_row7_col1\" class=\"data row7 col1\" >51.77%</td>\n",
       "      <td id=\"T_53c9e_row7_col2\" class=\"data row7 col2\" >49.55%</td>\n",
       "      <td id=\"T_53c9e_row7_col3\" class=\"data row7 col3\" >54.45%</td>\n",
       "      <td id=\"T_53c9e_row7_col4\" class=\"data row7 col4\" >49.59%</td>\n",
       "      <td id=\"T_53c9e_row7_col5\" class=\"data row7 col5\" >51.81%</td>\n",
       "      <td id=\"T_53c9e_row7_col6\" class=\"data row7 col6\" >48.97%</td>\n",
       "      <td id=\"T_53c9e_row7_col7\" class=\"data row7 col7\" >43.53%</td>\n",
       "      <td id=\"T_53c9e_row7_col8\" class=\"data row7 col8\" >43.92%</td>\n",
       "      <td id=\"T_53c9e_row7_col9\" class=\"data row7 col9\" >39.53%</td>\n",
       "      <td id=\"T_53c9e_row7_col10\" class=\"data row7 col10\" >50.33%</td>\n",
       "      <td id=\"T_53c9e_row7_col11\" class=\"data row7 col11\" >44.31%</td>\n",
       "      <td id=\"T_53c9e_row7_col12\" class=\"data row7 col12\" >39.41%</td>\n",
       "      <td id=\"T_53c9e_row7_col13\" class=\"data row7 col13\" >41.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row8\" class=\"row_heading level0 row8\" >spectral_rolloff</th>\n",
       "      <td id=\"T_53c9e_row8_col0\" class=\"data row8 col0\" >7.000000</td>\n",
       "      <td id=\"T_53c9e_row8_col1\" class=\"data row8 col1\" >41.78%</td>\n",
       "      <td id=\"T_53c9e_row8_col2\" class=\"data row8 col2\" >46.25%</td>\n",
       "      <td id=\"T_53c9e_row8_col3\" class=\"data row8 col3\" >47.53%</td>\n",
       "      <td id=\"T_53c9e_row8_col4\" class=\"data row8 col4\" >41.43%</td>\n",
       "      <td id=\"T_53c9e_row8_col5\" class=\"data row8 col5\" >41.62%</td>\n",
       "      <td id=\"T_53c9e_row8_col6\" class=\"data row8 col6\" >41.47%</td>\n",
       "      <td id=\"T_53c9e_row8_col7\" class=\"data row8 col7\" >45.36%</td>\n",
       "      <td id=\"T_53c9e_row8_col8\" class=\"data row8 col8\" >45.47%</td>\n",
       "      <td id=\"T_53c9e_row8_col9\" class=\"data row8 col9\" >41.66%</td>\n",
       "      <td id=\"T_53c9e_row8_col10\" class=\"data row8 col10\" >48.54%</td>\n",
       "      <td id=\"T_53c9e_row8_col11\" class=\"data row8 col11\" >47.65%</td>\n",
       "      <td id=\"T_53c9e_row8_col12\" class=\"data row8 col12\" >28.49%</td>\n",
       "      <td id=\"T_53c9e_row8_col13\" class=\"data row8 col13\" >28.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row9\" class=\"row_heading level0 row9\" >tonnetz</th>\n",
       "      <td id=\"T_53c9e_row9_col0\" class=\"data row9 col0\" >42.000000</td>\n",
       "      <td id=\"T_53c9e_row9_col1\" class=\"data row9 col1\" >40.11%</td>\n",
       "      <td id=\"T_53c9e_row9_col2\" class=\"data row9 col2\" >37.31%</td>\n",
       "      <td id=\"T_53c9e_row9_col3\" class=\"data row9 col3\" >42.25%</td>\n",
       "      <td id=\"T_53c9e_row9_col4\" class=\"data row9 col4\" >40.23%</td>\n",
       "      <td id=\"T_53c9e_row9_col5\" class=\"data row9 col5\" >40.15%</td>\n",
       "      <td id=\"T_53c9e_row9_col6\" class=\"data row9 col6\" >39.64%</td>\n",
       "      <td id=\"T_53c9e_row9_col7\" class=\"data row9 col7\" >35.91%</td>\n",
       "      <td id=\"T_53c9e_row9_col8\" class=\"data row9 col8\" >36.69%</td>\n",
       "      <td id=\"T_53c9e_row9_col9\" class=\"data row9 col9\" >34.16%</td>\n",
       "      <td id=\"T_53c9e_row9_col10\" class=\"data row9 col10\" >40.65%</td>\n",
       "      <td id=\"T_53c9e_row9_col11\" class=\"data row9 col11\" >31.79%</td>\n",
       "      <td id=\"T_53c9e_row9_col12\" class=\"data row9 col12\" >22.31%</td>\n",
       "      <td id=\"T_53c9e_row9_col13\" class=\"data row9 col13\" >23.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row10\" class=\"row_heading level0 row10\" >zcr</th>\n",
       "      <td id=\"T_53c9e_row10_col0\" class=\"data row10 col0\" >7.000000</td>\n",
       "      <td id=\"T_53c9e_row10_col1\" class=\"data row10 col1\" >43.41%</td>\n",
       "      <td id=\"T_53c9e_row10_col2\" class=\"data row10 col2\" >44.73%</td>\n",
       "      <td id=\"T_53c9e_row10_col3\" class=\"data row10 col3\" >45.43%</td>\n",
       "      <td id=\"T_53c9e_row10_col4\" class=\"data row10 col4\" >42.95%</td>\n",
       "      <td id=\"T_53c9e_row10_col5\" class=\"data row10 col5\" >42.67%</td>\n",
       "      <td id=\"T_53c9e_row10_col6\" class=\"data row10 col6\" >42.13%</td>\n",
       "      <td id=\"T_53c9e_row10_col7\" class=\"data row10 col7\" >43.61%</td>\n",
       "      <td id=\"T_53c9e_row10_col8\" class=\"data row10 col8\" >42.95%</td>\n",
       "      <td id=\"T_53c9e_row10_col9\" class=\"data row10 col9\" >40.89%</td>\n",
       "      <td id=\"T_53c9e_row10_col10\" class=\"data row10 col10\" >46.37%</td>\n",
       "      <td id=\"T_53c9e_row10_col11\" class=\"data row10 col11\" >44.77%</td>\n",
       "      <td id=\"T_53c9e_row10_col12\" class=\"data row10 col12\" >30.39%</td>\n",
       "      <td id=\"T_53c9e_row10_col13\" class=\"data row10 col13\" >32.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row11\" class=\"row_heading level0 row11\" >mfcc/contrast</th>\n",
       "      <td id=\"T_53c9e_row11_col0\" class=\"data row11 col0\" >189.000000</td>\n",
       "      <td id=\"T_53c9e_row11_col1\" class=\"data row11 col1\" >59.66%</td>\n",
       "      <td id=\"T_53c9e_row11_col2\" class=\"data row11 col2\" >55.31%</td>\n",
       "      <td id=\"T_53c9e_row11_col3\" class=\"data row11 col3\" >63.04%</td>\n",
       "      <td id=\"T_53c9e_row11_col4\" class=\"data row11 col4\" >61.02%</td>\n",
       "      <td id=\"T_53c9e_row11_col5\" class=\"data row11 col5\" >59.58%</td>\n",
       "      <td id=\"T_53c9e_row11_col6\" class=\"data row11 col6\" >58.84%</td>\n",
       "      <td id=\"T_53c9e_row11_col7\" class=\"data row11 col7\" >47.57%</td>\n",
       "      <td id=\"T_53c9e_row11_col8\" class=\"data row11 col8\" >44.97%</td>\n",
       "      <td id=\"T_53c9e_row11_col9\" class=\"data row11 col9\" >41.62%</td>\n",
       "      <td id=\"T_53c9e_row11_col10\" class=\"data row11 col10\" >53.09%</td>\n",
       "      <td id=\"T_53c9e_row11_col11\" class=\"data row11 col11\" >56.20%</td>\n",
       "      <td id=\"T_53c9e_row11_col12\" class=\"data row11 col12\" >44.03%</td>\n",
       "      <td id=\"T_53c9e_row11_col13\" class=\"data row11 col13\" >51.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row12\" class=\"row_heading level0 row12\" >mfcc/contrast/chroma</th>\n",
       "      <td id=\"T_53c9e_row12_col0\" class=\"data row12 col0\" >273.000000</td>\n",
       "      <td id=\"T_53c9e_row12_col1\" class=\"data row12 col1\" >60.05%</td>\n",
       "      <td id=\"T_53c9e_row12_col2\" class=\"data row12 col2\" >53.13%</td>\n",
       "      <td id=\"T_53c9e_row12_col3\" class=\"data row12 col3\" >62.92%</td>\n",
       "      <td id=\"T_53c9e_row12_col4\" class=\"data row12 col4\" >61.48%</td>\n",
       "      <td id=\"T_53c9e_row12_col5\" class=\"data row12 col5\" >59.11%</td>\n",
       "      <td id=\"T_53c9e_row12_col6\" class=\"data row12 col6\" >59.11%</td>\n",
       "      <td id=\"T_53c9e_row12_col7\" class=\"data row12 col7\" >47.57%</td>\n",
       "      <td id=\"T_53c9e_row12_col8\" class=\"data row12 col8\" >44.00%</td>\n",
       "      <td id=\"T_53c9e_row12_col9\" class=\"data row12 col9\" >41.62%</td>\n",
       "      <td id=\"T_53c9e_row12_col10\" class=\"data row12 col10\" >54.33%</td>\n",
       "      <td id=\"T_53c9e_row12_col11\" class=\"data row12 col11\" >58.14%</td>\n",
       "      <td id=\"T_53c9e_row12_col12\" class=\"data row12 col12\" >39.02%</td>\n",
       "      <td id=\"T_53c9e_row12_col13\" class=\"data row12 col13\" >51.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row13\" class=\"row_heading level0 row13\" >mfcc/contrast/centroid</th>\n",
       "      <td id=\"T_53c9e_row13_col0\" class=\"data row13 col0\" >196.000000</td>\n",
       "      <td id=\"T_53c9e_row13_col1\" class=\"data row13 col1\" >59.93%</td>\n",
       "      <td id=\"T_53c9e_row13_col2\" class=\"data row13 col2\" >55.23%</td>\n",
       "      <td id=\"T_53c9e_row13_col3\" class=\"data row13 col3\" >63.39%</td>\n",
       "      <td id=\"T_53c9e_row13_col4\" class=\"data row13 col4\" >61.48%</td>\n",
       "      <td id=\"T_53c9e_row13_col5\" class=\"data row13 col5\" >60.28%</td>\n",
       "      <td id=\"T_53c9e_row13_col6\" class=\"data row13 col6\" >59.00%</td>\n",
       "      <td id=\"T_53c9e_row13_col7\" class=\"data row13 col7\" >47.57%</td>\n",
       "      <td id=\"T_53c9e_row13_col8\" class=\"data row13 col8\" >46.33%</td>\n",
       "      <td id=\"T_53c9e_row13_col9\" class=\"data row13 col9\" >41.62%</td>\n",
       "      <td id=\"T_53c9e_row13_col10\" class=\"data row13 col10\" >53.28%</td>\n",
       "      <td id=\"T_53c9e_row13_col11\" class=\"data row13 col11\" >55.97%</td>\n",
       "      <td id=\"T_53c9e_row13_col12\" class=\"data row13 col12\" >43.76%</td>\n",
       "      <td id=\"T_53c9e_row13_col13\" class=\"data row13 col13\" >51.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row14\" class=\"row_heading level0 row14\" >mfcc/contrast/chroma/centroid</th>\n",
       "      <td id=\"T_53c9e_row14_col0\" class=\"data row14 col0\" >280.000000</td>\n",
       "      <td id=\"T_53c9e_row14_col1\" class=\"data row14 col1\" >60.01%</td>\n",
       "      <td id=\"T_53c9e_row14_col2\" class=\"data row14 col2\" >53.01%</td>\n",
       "      <td id=\"T_53c9e_row14_col3\" class=\"data row14 col3\" >63.08%</td>\n",
       "      <td id=\"T_53c9e_row14_col4\" class=\"data row14 col4\" >61.29%</td>\n",
       "      <td id=\"T_53c9e_row14_col5\" class=\"data row14 col5\" >60.12%</td>\n",
       "      <td id=\"T_53c9e_row14_col6\" class=\"data row14 col6\" >60.01%</td>\n",
       "      <td id=\"T_53c9e_row14_col7\" class=\"data row14 col7\" >47.57%</td>\n",
       "      <td id=\"T_53c9e_row14_col8\" class=\"data row14 col8\" >43.22%</td>\n",
       "      <td id=\"T_53c9e_row14_col9\" class=\"data row14 col9\" >41.62%</td>\n",
       "      <td id=\"T_53c9e_row14_col10\" class=\"data row14 col10\" >54.64%</td>\n",
       "      <td id=\"T_53c9e_row14_col11\" class=\"data row14 col11\" >58.03%</td>\n",
       "      <td id=\"T_53c9e_row14_col12\" class=\"data row14 col12\" >38.87%</td>\n",
       "      <td id=\"T_53c9e_row14_col13\" class=\"data row14 col13\" >51.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row15\" class=\"row_heading level0 row15\" >mfcc/contrast/chroma/centroid/tonnetz</th>\n",
       "      <td id=\"T_53c9e_row15_col0\" class=\"data row15 col0\" >322.000000</td>\n",
       "      <td id=\"T_53c9e_row15_col1\" class=\"data row15 col1\" >59.85%</td>\n",
       "      <td id=\"T_53c9e_row15_col2\" class=\"data row15 col2\" >52.62%</td>\n",
       "      <td id=\"T_53c9e_row15_col3\" class=\"data row15 col3\" >63.12%</td>\n",
       "      <td id=\"T_53c9e_row15_col4\" class=\"data row15 col4\" >62.50%</td>\n",
       "      <td id=\"T_53c9e_row15_col5\" class=\"data row15 col5\" >60.20%</td>\n",
       "      <td id=\"T_53c9e_row15_col6\" class=\"data row15 col6\" >59.85%</td>\n",
       "      <td id=\"T_53c9e_row15_col7\" class=\"data row15 col7\" >47.57%</td>\n",
       "      <td id=\"T_53c9e_row15_col8\" class=\"data row15 col8\" >42.09%</td>\n",
       "      <td id=\"T_53c9e_row15_col9\" class=\"data row15 col9\" >41.62%</td>\n",
       "      <td id=\"T_53c9e_row15_col10\" class=\"data row15 col10\" >54.84%</td>\n",
       "      <td id=\"T_53c9e_row15_col11\" class=\"data row15 col11\" >58.61%</td>\n",
       "      <td id=\"T_53c9e_row15_col12\" class=\"data row15 col12\" >39.06%</td>\n",
       "      <td id=\"T_53c9e_row15_col13\" class=\"data row15 col13\" >50.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row16\" class=\"row_heading level0 row16\" >mfcc/contrast/chroma/centroid/zcr</th>\n",
       "      <td id=\"T_53c9e_row16_col0\" class=\"data row16 col0\" >287.000000</td>\n",
       "      <td id=\"T_53c9e_row16_col1\" class=\"data row16 col1\" >60.55%</td>\n",
       "      <td id=\"T_53c9e_row16_col2\" class=\"data row16 col2\" >53.01%</td>\n",
       "      <td id=\"T_53c9e_row16_col3\" class=\"data row16 col3\" >62.81%</td>\n",
       "      <td id=\"T_53c9e_row16_col4\" class=\"data row16 col4\" >61.48%</td>\n",
       "      <td id=\"T_53c9e_row16_col5\" class=\"data row16 col5\" >59.77%</td>\n",
       "      <td id=\"T_53c9e_row16_col6\" class=\"data row16 col6\" >59.89%</td>\n",
       "      <td id=\"T_53c9e_row16_col7\" class=\"data row16 col7\" >47.69%</td>\n",
       "      <td id=\"T_53c9e_row16_col8\" class=\"data row16 col8\" >44.54%</td>\n",
       "      <td id=\"T_53c9e_row16_col9\" class=\"data row16 col9\" >41.62%</td>\n",
       "      <td id=\"T_53c9e_row16_col10\" class=\"data row16 col10\" >54.72%</td>\n",
       "      <td id=\"T_53c9e_row16_col11\" class=\"data row16 col11\" >57.99%</td>\n",
       "      <td id=\"T_53c9e_row16_col12\" class=\"data row16 col12\" >38.90%</td>\n",
       "      <td id=\"T_53c9e_row16_col13\" class=\"data row16 col13\" >51.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c9e_level0_row17\" class=\"row_heading level0 row17\" >all_non-echonest</th>\n",
       "      <td id=\"T_53c9e_row17_col0\" class=\"data row17 col0\" >518.000000</td>\n",
       "      <td id=\"T_53c9e_row17_col1\" class=\"data row17 col1\" >60.05%</td>\n",
       "      <td id=\"T_53c9e_row17_col2\" class=\"data row17 col2\" >51.77%</td>\n",
       "      <td id=\"T_53c9e_row17_col3\" class=\"data row17 col3\" >62.88%</td>\n",
       "      <td id=\"T_53c9e_row17_col4\" class=\"data row17 col4\" >61.95%</td>\n",
       "      <td id=\"T_53c9e_row17_col5\" class=\"data row17 col5\" >59.08%</td>\n",
       "      <td id=\"T_53c9e_row17_col6\" class=\"data row17 col6\" >59.93%</td>\n",
       "      <td id=\"T_53c9e_row17_col7\" class=\"data row17 col7\" >47.30%</td>\n",
       "      <td id=\"T_53c9e_row17_col8\" class=\"data row17 col8\" >43.14%</td>\n",
       "      <td id=\"T_53c9e_row17_col9\" class=\"data row17 col9\" >41.62%</td>\n",
       "      <td id=\"T_53c9e_row17_col10\" class=\"data row17 col10\" >55.85%</td>\n",
       "      <td id=\"T_53c9e_row17_col11\" class=\"data row17 col11\" >55.97%</td>\n",
       "      <td id=\"T_53c9e_row17_col12\" class=\"data row17 col12\" >9.91%</td>\n",
       "      <td id=\"T_53c9e_row17_col13\" class=\"data row17 col13\" >19.47%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f96bbdb100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e0340\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e0340_level0_col0\" class=\"col_heading level0 col0\" >LR</th>\n",
       "      <th id=\"T_e0340_level0_col1\" class=\"col_heading level0 col1\" >kNN</th>\n",
       "      <th id=\"T_e0340_level0_col2\" class=\"col_heading level0 col2\" >SVCrbf</th>\n",
       "      <th id=\"T_e0340_level0_col3\" class=\"col_heading level0 col3\" >SVCpoly1</th>\n",
       "      <th id=\"T_e0340_level0_col4\" class=\"col_heading level0 col4\" >linSVC1</th>\n",
       "      <th id=\"T_e0340_level0_col5\" class=\"col_heading level0 col5\" >linSVC2</th>\n",
       "      <th id=\"T_e0340_level0_col6\" class=\"col_heading level0 col6\" >DT</th>\n",
       "      <th id=\"T_e0340_level0_col7\" class=\"col_heading level0 col7\" >RF</th>\n",
       "      <th id=\"T_e0340_level0_col8\" class=\"col_heading level0 col8\" >AdaBoost</th>\n",
       "      <th id=\"T_e0340_level0_col9\" class=\"col_heading level0 col9\" >MLP1</th>\n",
       "      <th id=\"T_e0340_level0_col10\" class=\"col_heading level0 col10\" >MLP2</th>\n",
       "      <th id=\"T_e0340_level0_col11\" class=\"col_heading level0 col11\" >NB</th>\n",
       "      <th id=\"T_e0340_level0_col12\" class=\"col_heading level0 col12\" >QDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "      <td id=\"T_e0340_row0_col0\" class=\"data row0 col0\" >9.8750</td>\n",
       "      <td id=\"T_e0340_row0_col1\" class=\"data row0 col1\" >4.3125</td>\n",
       "      <td id=\"T_e0340_row0_col2\" class=\"data row0 col2\" >73.8281</td>\n",
       "      <td id=\"T_e0340_row0_col3\" class=\"data row0 col3\" >60.0000</td>\n",
       "      <td id=\"T_e0340_row0_col4\" class=\"data row0 col4\" >274.0938</td>\n",
       "      <td id=\"T_e0340_row0_col5\" class=\"data row0 col5\" >134.4375</td>\n",
       "      <td id=\"T_e0340_row0_col6\" class=\"data row0 col6\" >3.5469</td>\n",
       "      <td id=\"T_e0340_row0_col7\" class=\"data row0 col7\" >0.3906</td>\n",
       "      <td id=\"T_e0340_row0_col8\" class=\"data row0 col8\" >9.0469</td>\n",
       "      <td id=\"T_e0340_row0_col9\" class=\"data row0 col9\" >148.4844</td>\n",
       "      <td id=\"T_e0340_row0_col10\" class=\"data row0 col10\" >123.3438</td>\n",
       "      <td id=\"T_e0340_row0_col11\" class=\"data row0 col11\" >0.0938</td>\n",
       "      <td id=\"T_e0340_row0_col12\" class=\"data row0 col12\" >0.1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row1\" class=\"row_heading level0 row1\" >chroma_cqt</th>\n",
       "      <td id=\"T_e0340_row1_col0\" class=\"data row1 col0\" >10.4844</td>\n",
       "      <td id=\"T_e0340_row1_col1\" class=\"data row1 col1\" >3.8438</td>\n",
       "      <td id=\"T_e0340_row1_col2\" class=\"data row1 col2\" >80.5625</td>\n",
       "      <td id=\"T_e0340_row1_col3\" class=\"data row1 col3\" >73.5781</td>\n",
       "      <td id=\"T_e0340_row1_col4\" class=\"data row1 col4\" >416.9844</td>\n",
       "      <td id=\"T_e0340_row1_col5\" class=\"data row1 col5\" >131.7812</td>\n",
       "      <td id=\"T_e0340_row1_col6\" class=\"data row1 col6\" >3.2969</td>\n",
       "      <td id=\"T_e0340_row1_col7\" class=\"data row1 col7\" >0.3594</td>\n",
       "      <td id=\"T_e0340_row1_col8\" class=\"data row1 col8\" >8.5312</td>\n",
       "      <td id=\"T_e0340_row1_col9\" class=\"data row1 col9\" >95.7031</td>\n",
       "      <td id=\"T_e0340_row1_col10\" class=\"data row1 col10\" >114.1875</td>\n",
       "      <td id=\"T_e0340_row1_col11\" class=\"data row1 col11\" >0.0938</td>\n",
       "      <td id=\"T_e0340_row1_col12\" class=\"data row1 col12\" >0.1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row2\" class=\"row_heading level0 row2\" >chroma_stft</th>\n",
       "      <td id=\"T_e0340_row2_col0\" class=\"data row2 col0\" >1.7031</td>\n",
       "      <td id=\"T_e0340_row2_col1\" class=\"data row2 col1\" >3.6250</td>\n",
       "      <td id=\"T_e0340_row2_col2\" class=\"data row2 col2\" >64.5000</td>\n",
       "      <td id=\"T_e0340_row2_col3\" class=\"data row2 col3\" >64.7500</td>\n",
       "      <td id=\"T_e0340_row2_col4\" class=\"data row2 col4\" >257.8750</td>\n",
       "      <td id=\"T_e0340_row2_col5\" class=\"data row2 col5\" >125.5938</td>\n",
       "      <td id=\"T_e0340_row2_col6\" class=\"data row2 col6\" >3.2812</td>\n",
       "      <td id=\"T_e0340_row2_col7\" class=\"data row2 col7\" >0.4219</td>\n",
       "      <td id=\"T_e0340_row2_col8\" class=\"data row2 col8\" >8.4375</td>\n",
       "      <td id=\"T_e0340_row2_col9\" class=\"data row2 col9\" >83.4062</td>\n",
       "      <td id=\"T_e0340_row2_col10\" class=\"data row2 col10\" >100.7812</td>\n",
       "      <td id=\"T_e0340_row2_col11\" class=\"data row2 col11\" >0.0781</td>\n",
       "      <td id=\"T_e0340_row2_col12\" class=\"data row2 col12\" >0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row3\" class=\"row_heading level0 row3\" >mfcc</th>\n",
       "      <td id=\"T_e0340_row3_col0\" class=\"data row3 col0\" >13.1094</td>\n",
       "      <td id=\"T_e0340_row3_col1\" class=\"data row3 col1\" >4.8281</td>\n",
       "      <td id=\"T_e0340_row3_col2\" class=\"data row3 col2\" >90.2031</td>\n",
       "      <td id=\"T_e0340_row3_col3\" class=\"data row3 col3\" >65.2031</td>\n",
       "      <td id=\"T_e0340_row3_col4\" class=\"data row3 col4\" >243.1562</td>\n",
       "      <td id=\"T_e0340_row3_col5\" class=\"data row3 col5\" >136.0469</td>\n",
       "      <td id=\"T_e0340_row3_col6\" class=\"data row3 col6\" >6.3906</td>\n",
       "      <td id=\"T_e0340_row3_col7\" class=\"data row3 col7\" >0.4219</td>\n",
       "      <td id=\"T_e0340_row3_col8\" class=\"data row3 col8\" >17.2500</td>\n",
       "      <td id=\"T_e0340_row3_col9\" class=\"data row3 col9\" >166.7656</td>\n",
       "      <td id=\"T_e0340_row3_col10\" class=\"data row3 col10\" >54.5000</td>\n",
       "      <td id=\"T_e0340_row3_col11\" class=\"data row3 col11\" >0.1406</td>\n",
       "      <td id=\"T_e0340_row3_col12\" class=\"data row3 col12\" >0.3594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row4\" class=\"row_heading level0 row4\" >rmse</th>\n",
       "      <td id=\"T_e0340_row4_col0\" class=\"data row4 col0\" >1.2812</td>\n",
       "      <td id=\"T_e0340_row4_col1\" class=\"data row4 col1\" >0.7812</td>\n",
       "      <td id=\"T_e0340_row4_col2\" class=\"data row4 col2\" >43.6406</td>\n",
       "      <td id=\"T_e0340_row4_col3\" class=\"data row4 col3\" >25.9531</td>\n",
       "      <td id=\"T_e0340_row4_col4\" class=\"data row4 col4\" >31.0781</td>\n",
       "      <td id=\"T_e0340_row4_col5\" class=\"data row4 col5\" >17.9219</td>\n",
       "      <td id=\"T_e0340_row4_col6\" class=\"data row4 col6\" >0.2969</td>\n",
       "      <td id=\"T_e0340_row4_col7\" class=\"data row4 col7\" >0.4062</td>\n",
       "      <td id=\"T_e0340_row4_col8\" class=\"data row4 col8\" >1.1562</td>\n",
       "      <td id=\"T_e0340_row4_col9\" class=\"data row4 col9\" >64.4531</td>\n",
       "      <td id=\"T_e0340_row4_col10\" class=\"data row4 col10\" >247.0938</td>\n",
       "      <td id=\"T_e0340_row4_col11\" class=\"data row4 col11\" >0.0000</td>\n",
       "      <td id=\"T_e0340_row4_col12\" class=\"data row4 col12\" >0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row5\" class=\"row_heading level0 row5\" >spectral_bandwidth</th>\n",
       "      <td id=\"T_e0340_row5_col0\" class=\"data row5 col0\" >1.7344</td>\n",
       "      <td id=\"T_e0340_row5_col1\" class=\"data row5 col1\" >0.6875</td>\n",
       "      <td id=\"T_e0340_row5_col2\" class=\"data row5 col2\" >44.1875</td>\n",
       "      <td id=\"T_e0340_row5_col3\" class=\"data row5 col3\" >26.7656</td>\n",
       "      <td id=\"T_e0340_row5_col4\" class=\"data row5 col4\" >38.2344</td>\n",
       "      <td id=\"T_e0340_row5_col5\" class=\"data row5 col5\" >19.2344</td>\n",
       "      <td id=\"T_e0340_row5_col6\" class=\"data row5 col6\" >0.3125</td>\n",
       "      <td id=\"T_e0340_row5_col7\" class=\"data row5 col7\" >0.4062</td>\n",
       "      <td id=\"T_e0340_row5_col8\" class=\"data row5 col8\" >1.1250</td>\n",
       "      <td id=\"T_e0340_row5_col9\" class=\"data row5 col9\" >68.6562</td>\n",
       "      <td id=\"T_e0340_row5_col10\" class=\"data row5 col10\" >91.2500</td>\n",
       "      <td id=\"T_e0340_row5_col11\" class=\"data row5 col11\" >0.0000</td>\n",
       "      <td id=\"T_e0340_row5_col12\" class=\"data row5 col12\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row6\" class=\"row_heading level0 row6\" >spectral_centroid</th>\n",
       "      <td id=\"T_e0340_row6_col0\" class=\"data row6 col0\" >1.7344</td>\n",
       "      <td id=\"T_e0340_row6_col1\" class=\"data row6 col1\" >0.7344</td>\n",
       "      <td id=\"T_e0340_row6_col2\" class=\"data row6 col2\" >41.7812</td>\n",
       "      <td id=\"T_e0340_row6_col3\" class=\"data row6 col3\" >29.0625</td>\n",
       "      <td id=\"T_e0340_row6_col4\" class=\"data row6 col4\" >39.2031</td>\n",
       "      <td id=\"T_e0340_row6_col5\" class=\"data row6 col5\" >18.2344</td>\n",
       "      <td id=\"T_e0340_row6_col6\" class=\"data row6 col6\" >0.2969</td>\n",
       "      <td id=\"T_e0340_row6_col7\" class=\"data row6 col7\" >0.4062</td>\n",
       "      <td id=\"T_e0340_row6_col8\" class=\"data row6 col8\" >1.1406</td>\n",
       "      <td id=\"T_e0340_row6_col9\" class=\"data row6 col9\" >52.0000</td>\n",
       "      <td id=\"T_e0340_row6_col10\" class=\"data row6 col10\" >419.0938</td>\n",
       "      <td id=\"T_e0340_row6_col11\" class=\"data row6 col11\" >0.0000</td>\n",
       "      <td id=\"T_e0340_row6_col12\" class=\"data row6 col12\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row7\" class=\"row_heading level0 row7\" >spectral_contrast</th>\n",
       "      <td id=\"T_e0340_row7_col0\" class=\"data row7 col0\" >8.6875</td>\n",
       "      <td id=\"T_e0340_row7_col1\" class=\"data row7 col1\" >3.7031</td>\n",
       "      <td id=\"T_e0340_row7_col2\" class=\"data row7 col2\" >42.2031</td>\n",
       "      <td id=\"T_e0340_row7_col3\" class=\"data row7 col3\" >35.6875</td>\n",
       "      <td id=\"T_e0340_row7_col4\" class=\"data row7 col4\" >89.2188</td>\n",
       "      <td id=\"T_e0340_row7_col5\" class=\"data row7 col5\" >62.5000</td>\n",
       "      <td id=\"T_e0340_row7_col6\" class=\"data row7 col6\" >2.3125</td>\n",
       "      <td id=\"T_e0340_row7_col7\" class=\"data row7 col7\" >0.5312</td>\n",
       "      <td id=\"T_e0340_row7_col8\" class=\"data row7 col8\" >6.3125</td>\n",
       "      <td id=\"T_e0340_row7_col9\" class=\"data row7 col9\" >135.4375</td>\n",
       "      <td id=\"T_e0340_row7_col10\" class=\"data row7 col10\" >159.6250</td>\n",
       "      <td id=\"T_e0340_row7_col11\" class=\"data row7 col11\" >0.0000</td>\n",
       "      <td id=\"T_e0340_row7_col12\" class=\"data row7 col12\" >0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row8\" class=\"row_heading level0 row8\" >spectral_rolloff</th>\n",
       "      <td id=\"T_e0340_row8_col0\" class=\"data row8 col0\" >1.0156</td>\n",
       "      <td id=\"T_e0340_row8_col1\" class=\"data row8 col1\" >0.7031</td>\n",
       "      <td id=\"T_e0340_row8_col2\" class=\"data row8 col2\" >41.2500</td>\n",
       "      <td id=\"T_e0340_row8_col3\" class=\"data row8 col3\" >25.9375</td>\n",
       "      <td id=\"T_e0340_row8_col4\" class=\"data row8 col4\" >35.8750</td>\n",
       "      <td id=\"T_e0340_row8_col5\" class=\"data row8 col5\" >18.3750</td>\n",
       "      <td id=\"T_e0340_row8_col6\" class=\"data row8 col6\" >0.2031</td>\n",
       "      <td id=\"T_e0340_row8_col7\" class=\"data row8 col7\" >0.3125</td>\n",
       "      <td id=\"T_e0340_row8_col8\" class=\"data row8 col8\" >0.9375</td>\n",
       "      <td id=\"T_e0340_row8_col9\" class=\"data row8 col9\" >62.3594</td>\n",
       "      <td id=\"T_e0340_row8_col10\" class=\"data row8 col10\" >169.1406</td>\n",
       "      <td id=\"T_e0340_row8_col11\" class=\"data row8 col11\" >0.0000</td>\n",
       "      <td id=\"T_e0340_row8_col12\" class=\"data row8 col12\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row9\" class=\"row_heading level0 row9\" >tonnetz</th>\n",
       "      <td id=\"T_e0340_row9_col0\" class=\"data row9 col0\" >0.8281</td>\n",
       "      <td id=\"T_e0340_row9_col1\" class=\"data row9 col1\" >3.5938</td>\n",
       "      <td id=\"T_e0340_row9_col2\" class=\"data row9 col2\" >54.5625</td>\n",
       "      <td id=\"T_e0340_row9_col3\" class=\"data row9 col3\" >38.3906</td>\n",
       "      <td id=\"T_e0340_row9_col4\" class=\"data row9 col4\" >94.7656</td>\n",
       "      <td id=\"T_e0340_row9_col5\" class=\"data row9 col5\" >63.7812</td>\n",
       "      <td id=\"T_e0340_row9_col6\" class=\"data row9 col6\" >1.8438</td>\n",
       "      <td id=\"T_e0340_row9_col7\" class=\"data row9 col7\" >0.4219</td>\n",
       "      <td id=\"T_e0340_row9_col8\" class=\"data row9 col8\" >5.2344</td>\n",
       "      <td id=\"T_e0340_row9_col9\" class=\"data row9 col9\" >86.8594</td>\n",
       "      <td id=\"T_e0340_row9_col10\" class=\"data row9 col10\" >176.2812</td>\n",
       "      <td id=\"T_e0340_row9_col11\" class=\"data row9 col11\" >0.0469</td>\n",
       "      <td id=\"T_e0340_row9_col12\" class=\"data row9 col12\" >0.0781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row10\" class=\"row_heading level0 row10\" >zcr</th>\n",
       "      <td id=\"T_e0340_row10_col0\" class=\"data row10 col0\" >1.4219</td>\n",
       "      <td id=\"T_e0340_row10_col1\" class=\"data row10 col1\" >0.7031</td>\n",
       "      <td id=\"T_e0340_row10_col2\" class=\"data row10 col2\" >42.7812</td>\n",
       "      <td id=\"T_e0340_row10_col3\" class=\"data row10 col3\" >27.8594</td>\n",
       "      <td id=\"T_e0340_row10_col4\" class=\"data row10 col4\" >36.2812</td>\n",
       "      <td id=\"T_e0340_row10_col5\" class=\"data row10 col5\" >19.3281</td>\n",
       "      <td id=\"T_e0340_row10_col6\" class=\"data row10 col6\" >0.2344</td>\n",
       "      <td id=\"T_e0340_row10_col7\" class=\"data row10 col7\" >0.2344</td>\n",
       "      <td id=\"T_e0340_row10_col8\" class=\"data row10 col8\" >0.9844</td>\n",
       "      <td id=\"T_e0340_row10_col9\" class=\"data row10 col9\" >62.5156</td>\n",
       "      <td id=\"T_e0340_row10_col10\" class=\"data row10 col10\" >389.6562</td>\n",
       "      <td id=\"T_e0340_row10_col11\" class=\"data row10 col11\" >0.0000</td>\n",
       "      <td id=\"T_e0340_row10_col12\" class=\"data row10 col12\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row11\" class=\"row_heading level0 row11\" >mfcc/contrast</th>\n",
       "      <td id=\"T_e0340_row11_col0\" class=\"data row11 col0\" >14.6562</td>\n",
       "      <td id=\"T_e0340_row11_col1\" class=\"data row11 col1\" >5.7344</td>\n",
       "      <td id=\"T_e0340_row11_col2\" class=\"data row11 col2\" >107.8750</td>\n",
       "      <td id=\"T_e0340_row11_col3\" class=\"data row11 col3\" >84.3750</td>\n",
       "      <td id=\"T_e0340_row11_col4\" class=\"data row11 col4\" >349.3281</td>\n",
       "      <td id=\"T_e0340_row11_col5\" class=\"data row11 col5\" >150.2344</td>\n",
       "      <td id=\"T_e0340_row11_col6\" class=\"data row11 col6\" >9.3750</td>\n",
       "      <td id=\"T_e0340_row11_col7\" class=\"data row11 col7\" >0.5312</td>\n",
       "      <td id=\"T_e0340_row11_col8\" class=\"data row11 col8\" >25.2344</td>\n",
       "      <td id=\"T_e0340_row11_col9\" class=\"data row11 col9\" >121.5781</td>\n",
       "      <td id=\"T_e0340_row11_col10\" class=\"data row11 col10\" >44.9062</td>\n",
       "      <td id=\"T_e0340_row11_col11\" class=\"data row11 col11\" >0.0781</td>\n",
       "      <td id=\"T_e0340_row11_col12\" class=\"data row11 col12\" >0.2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row12\" class=\"row_heading level0 row12\" >mfcc/contrast/chroma</th>\n",
       "      <td id=\"T_e0340_row12_col0\" class=\"data row12 col0\" >26.8125</td>\n",
       "      <td id=\"T_e0340_row12_col1\" class=\"data row12 col1\" >6.5781</td>\n",
       "      <td id=\"T_e0340_row12_col2\" class=\"data row12 col2\" >136.6719</td>\n",
       "      <td id=\"T_e0340_row12_col3\" class=\"data row12 col3\" >108.4844</td>\n",
       "      <td id=\"T_e0340_row12_col4\" class=\"data row12 col4\" >519.7188</td>\n",
       "      <td id=\"T_e0340_row12_col5\" class=\"data row12 col5\" >177.9844</td>\n",
       "      <td id=\"T_e0340_row12_col6\" class=\"data row12 col6\" >12.2188</td>\n",
       "      <td id=\"T_e0340_row12_col7\" class=\"data row12 col7\" >0.4219</td>\n",
       "      <td id=\"T_e0340_row12_col8\" class=\"data row12 col8\" >30.7812</td>\n",
       "      <td id=\"T_e0340_row12_col9\" class=\"data row12 col9\" >59.6094</td>\n",
       "      <td id=\"T_e0340_row12_col10\" class=\"data row12 col10\" >32.8906</td>\n",
       "      <td id=\"T_e0340_row12_col11\" class=\"data row12 col11\" >0.2344</td>\n",
       "      <td id=\"T_e0340_row12_col12\" class=\"data row12 col12\" >1.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row13\" class=\"row_heading level0 row13\" >mfcc/contrast/centroid</th>\n",
       "      <td id=\"T_e0340_row13_col0\" class=\"data row13 col0\" >16.4219</td>\n",
       "      <td id=\"T_e0340_row13_col1\" class=\"data row13 col1\" >5.6094</td>\n",
       "      <td id=\"T_e0340_row13_col2\" class=\"data row13 col2\" >108.0156</td>\n",
       "      <td id=\"T_e0340_row13_col3\" class=\"data row13 col3\" >85.5625</td>\n",
       "      <td id=\"T_e0340_row13_col4\" class=\"data row13 col4\" >323.4219</td>\n",
       "      <td id=\"T_e0340_row13_col5\" class=\"data row13 col5\" >144.1250</td>\n",
       "      <td id=\"T_e0340_row13_col6\" class=\"data row13 col6\" >8.9375</td>\n",
       "      <td id=\"T_e0340_row13_col7\" class=\"data row13 col7\" >0.4375</td>\n",
       "      <td id=\"T_e0340_row13_col8\" class=\"data row13 col8\" >23.0000</td>\n",
       "      <td id=\"T_e0340_row13_col9\" class=\"data row13 col9\" >121.5625</td>\n",
       "      <td id=\"T_e0340_row13_col10\" class=\"data row13 col10\" >40.7500</td>\n",
       "      <td id=\"T_e0340_row13_col11\" class=\"data row13 col11\" >0.1875</td>\n",
       "      <td id=\"T_e0340_row13_col12\" class=\"data row13 col12\" >0.7344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row14\" class=\"row_heading level0 row14\" >mfcc/contrast/chroma/centroid</th>\n",
       "      <td id=\"T_e0340_row14_col0\" class=\"data row14 col0\" >22.9062</td>\n",
       "      <td id=\"T_e0340_row14_col1\" class=\"data row14 col1\" >6.7031</td>\n",
       "      <td id=\"T_e0340_row14_col2\" class=\"data row14 col2\" >134.2031</td>\n",
       "      <td id=\"T_e0340_row14_col3\" class=\"data row14 col3\" >106.8750</td>\n",
       "      <td id=\"T_e0340_row14_col4\" class=\"data row14 col4\" >521.0781</td>\n",
       "      <td id=\"T_e0340_row14_col5\" class=\"data row14 col5\" >179.4844</td>\n",
       "      <td id=\"T_e0340_row14_col6\" class=\"data row14 col6\" >12.5781</td>\n",
       "      <td id=\"T_e0340_row14_col7\" class=\"data row14 col7\" >0.4375</td>\n",
       "      <td id=\"T_e0340_row14_col8\" class=\"data row14 col8\" >31.6094</td>\n",
       "      <td id=\"T_e0340_row14_col9\" class=\"data row14 col9\" >60.7500</td>\n",
       "      <td id=\"T_e0340_row14_col10\" class=\"data row14 col10\" >33.1562</td>\n",
       "      <td id=\"T_e0340_row14_col11\" class=\"data row14 col11\" >0.2500</td>\n",
       "      <td id=\"T_e0340_row14_col12\" class=\"data row14 col12\" >1.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row15\" class=\"row_heading level0 row15\" >mfcc/contrast/chroma/centroid/tonnetz</th>\n",
       "      <td id=\"T_e0340_row15_col0\" class=\"data row15 col0\" >8.2656</td>\n",
       "      <td id=\"T_e0340_row15_col1\" class=\"data row15 col1\" >7.1719</td>\n",
       "      <td id=\"T_e0340_row15_col2\" class=\"data row15 col2\" >147.4062</td>\n",
       "      <td id=\"T_e0340_row15_col3\" class=\"data row15 col3\" >115.3438</td>\n",
       "      <td id=\"T_e0340_row15_col4\" class=\"data row15 col4\" >590.4844</td>\n",
       "      <td id=\"T_e0340_row15_col5\" class=\"data row15 col5\" >194.9844</td>\n",
       "      <td id=\"T_e0340_row15_col6\" class=\"data row15 col6\" >14.2969</td>\n",
       "      <td id=\"T_e0340_row15_col7\" class=\"data row15 col7\" >0.4375</td>\n",
       "      <td id=\"T_e0340_row15_col8\" class=\"data row15 col8\" >36.5312</td>\n",
       "      <td id=\"T_e0340_row15_col9\" class=\"data row15 col9\" >64.8125</td>\n",
       "      <td id=\"T_e0340_row15_col10\" class=\"data row15 col10\" >37.6406</td>\n",
       "      <td id=\"T_e0340_row15_col11\" class=\"data row15 col11\" >0.2656</td>\n",
       "      <td id=\"T_e0340_row15_col12\" class=\"data row15 col12\" >1.5312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row16\" class=\"row_heading level0 row16\" >mfcc/contrast/chroma/centroid/zcr</th>\n",
       "      <td id=\"T_e0340_row16_col0\" class=\"data row16 col0\" >5.8125</td>\n",
       "      <td id=\"T_e0340_row16_col1\" class=\"data row16 col1\" >6.9688</td>\n",
       "      <td id=\"T_e0340_row16_col2\" class=\"data row16 col2\" >136.0625</td>\n",
       "      <td id=\"T_e0340_row16_col3\" class=\"data row16 col3\" >106.3594</td>\n",
       "      <td id=\"T_e0340_row16_col4\" class=\"data row16 col4\" >524.9062</td>\n",
       "      <td id=\"T_e0340_row16_col5\" class=\"data row16 col5\" >182.5938</td>\n",
       "      <td id=\"T_e0340_row16_col6\" class=\"data row16 col6\" >12.7969</td>\n",
       "      <td id=\"T_e0340_row16_col7\" class=\"data row16 col7\" >0.4375</td>\n",
       "      <td id=\"T_e0340_row16_col8\" class=\"data row16 col8\" >32.1719</td>\n",
       "      <td id=\"T_e0340_row16_col9\" class=\"data row16 col9\" >80.7656</td>\n",
       "      <td id=\"T_e0340_row16_col10\" class=\"data row16 col10\" >39.8906</td>\n",
       "      <td id=\"T_e0340_row16_col11\" class=\"data row16 col11\" >0.2344</td>\n",
       "      <td id=\"T_e0340_row16_col12\" class=\"data row16 col12\" >1.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0340_level0_row17\" class=\"row_heading level0 row17\" >all_non-echonest</th>\n",
       "      <td id=\"T_e0340_row17_col0\" class=\"data row17 col0\" >22.1562</td>\n",
       "      <td id=\"T_e0340_row17_col1\" class=\"data row17 col1\" >9.9531</td>\n",
       "      <td id=\"T_e0340_row17_col2\" class=\"data row17 col2\" >205.8125</td>\n",
       "      <td id=\"T_e0340_row17_col3\" class=\"data row17 col3\" >161.0938</td>\n",
       "      <td id=\"T_e0340_row17_col4\" class=\"data row17 col4\" >845.1250</td>\n",
       "      <td id=\"T_e0340_row17_col5\" class=\"data row17 col5\" >276.6250</td>\n",
       "      <td id=\"T_e0340_row17_col6\" class=\"data row17 col6\" >21.7812</td>\n",
       "      <td id=\"T_e0340_row17_col7\" class=\"data row17 col7\" >0.4375</td>\n",
       "      <td id=\"T_e0340_row17_col8\" class=\"data row17 col8\" >55.1719</td>\n",
       "      <td id=\"T_e0340_row17_col9\" class=\"data row17 col9\" >57.9375</td>\n",
       "      <td id=\"T_e0340_row17_col10\" class=\"data row17 col10\" >35.2188</td>\n",
       "      <td id=\"T_e0340_row17_col11\" class=\"data row17 col11\" >0.4531</td>\n",
       "      <td id=\"T_e0340_row17_col12\" class=\"data row17 col12\" >3.7344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f96bbdbd00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'LR': LogisticRegression(max_iter=500),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=200),\n",
    "    'SVCrbf': SVC(kernel='rbf'),\n",
    "    'SVCpoly1': SVC(kernel='poly', degree=1),\n",
    "    'linSVC1': SVC(kernel=\"linear\"),\n",
    "    'linSVC2': LinearSVC(),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    'DT': DecisionTreeClassifier(max_depth=5),\n",
    "    'RF': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
    "    'MLP1': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "    'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "    'NB': GaussianNB(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_social': ('echonest', 'social_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "#    'echonest_audio/social': ('echonest', ('audio_features', 'social_features')),\n",
    "#    'echonest_all': ('echonest', ('audio_features', 'social_features', 'temporal_features')),\n",
    "}\n",
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Multiple genres\n",
    "\n",
    "Todo:\n",
    "* Ignore rare genres? Count them higher up in the genre tree? On the other hand it's not much tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bc2c6b13394657ab180997b98660cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "features:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (700) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5071c_row0_col2, #T_5071c_row1_col2, #T_5071c_row2_col2 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5071c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5071c_level0_col0\" class=\"col_heading level0 col0\" >dim</th>\n",
       "      <th id=\"T_5071c_level0_col1\" class=\"col_heading level0 col1\" >LR</th>\n",
       "      <th id=\"T_5071c_level0_col2\" class=\"col_heading level0 col2\" >SVC</th>\n",
       "      <th id=\"T_5071c_level0_col3\" class=\"col_heading level0 col3\" >MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5071c_level0_row0\" class=\"row_heading level0 row0\" >mfcc</th>\n",
       "      <td id=\"T_5071c_row0_col0\" class=\"data row0 col0\" >140.000000</td>\n",
       "      <td id=\"T_5071c_row0_col1\" class=\"data row0 col1\" >11.19%</td>\n",
       "      <td id=\"T_5071c_row0_col2\" class=\"data row0 col2\" >12.13%</td>\n",
       "      <td id=\"T_5071c_row0_col3\" class=\"data row0 col3\" >10.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5071c_level0_row1\" class=\"row_heading level0 row1\" >mfcc/contrast/chroma/centroid/tonnetz</th>\n",
       "      <td id=\"T_5071c_row1_col0\" class=\"data row1 col0\" >322.000000</td>\n",
       "      <td id=\"T_5071c_row1_col1\" class=\"data row1 col1\" >12.98%</td>\n",
       "      <td id=\"T_5071c_row1_col2\" class=\"data row1 col2\" >13.41%</td>\n",
       "      <td id=\"T_5071c_row1_col3\" class=\"data row1 col3\" >8.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5071c_level0_row2\" class=\"row_heading level0 row2\" >mfcc/contrast/chroma/centroid/zcr</th>\n",
       "      <td id=\"T_5071c_row2_col0\" class=\"data row2 col0\" >287.000000</td>\n",
       "      <td id=\"T_5071c_row2_col1\" class=\"data row2 col1\" >12.90%</td>\n",
       "      <td id=\"T_5071c_row2_col2\" class=\"data row2 col2\" >13.64%</td>\n",
       "      <td id=\"T_5071c_row2_col3\" class=\"data row2 col3\" >9.56%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f95705e730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_47ac9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_47ac9_level0_col0\" class=\"col_heading level0 col0\" >LR</th>\n",
       "      <th id=\"T_47ac9_level0_col1\" class=\"col_heading level0 col1\" >SVC</th>\n",
       "      <th id=\"T_47ac9_level0_col2\" class=\"col_heading level0 col2\" >MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_47ac9_level0_row0\" class=\"row_heading level0 row0\" >mfcc</th>\n",
       "      <td id=\"T_47ac9_row0_col0\" class=\"data row0 col0\" >31.0625</td>\n",
       "      <td id=\"T_47ac9_row0_col1\" class=\"data row0 col1\" >1114.2969</td>\n",
       "      <td id=\"T_47ac9_row0_col2\" class=\"data row0 col2\" >324.2969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_47ac9_level0_row1\" class=\"row_heading level0 row1\" >mfcc/contrast/chroma/centroid/tonnetz</th>\n",
       "      <td id=\"T_47ac9_row1_col0\" class=\"data row1 col0\" >115.7188</td>\n",
       "      <td id=\"T_47ac9_row1_col1\" class=\"data row1 col1\" >2576.6406</td>\n",
       "      <td id=\"T_47ac9_row1_col2\" class=\"data row1 col2\" >394.3594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_47ac9_level0_row2\" class=\"row_heading level0 row2\" >mfcc/contrast/chroma/centroid/zcr</th>\n",
       "      <td id=\"T_47ac9_row2_col0\" class=\"data row2 col0\" >147.2656</td>\n",
       "      <td id=\"T_47ac9_row2_col1\" class=\"data row2 col1\" >2241.5781</td>\n",
       "      <td id=\"T_47ac9_row2_col2\" class=\"data row2 col2\" >322.5469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f96b922040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = {\n",
    "    #LogisticRegression(),\n",
    "    'LR': OneVsRestClassifier(LogisticRegression(max_iter= 1000)),\n",
    "    'SVC': OneVsRestClassifier(SVC()),\n",
    "    'MLP': MLPClassifier(max_iter=700),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "    'mfcc': 'mfcc',\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "}\n",
    "\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets, multi_label=True)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Build the CNN Model\n",
    "Construct a simple Convolutional Neural Network (CNN) that consists of three convolutional layers and two fully connected layers to identify genres from music features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGenreCNN(nn.Module):\n",
    "    def __init__(self, num_classes=16):\n",
    "        super(MusicGenreCNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "        )\n",
    "        \n",
    "        self.fc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if self.fc is None:\n",
    "            num_features = x.shape[1]\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(num_features, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, self.num_classes)\n",
    "            )\n",
    "            self.fc = self.fc.to(x.device)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train and evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, tracks, features_all, features, device,\n",
    "                multi_label=False, epochs=30, batch_size=64, patience = 10):\n",
    "    y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, features, multi_label)\n",
    "    \n",
    "    # Convert arrays to PyTorch tensors\n",
    "    X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)\n",
    "    X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    # Create TensorDataset\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # move the model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # history\n",
    "    history = {'train_loss': [],\n",
    "              'train_acc': [],\n",
    "              'valid_loss': [],\n",
    "              'valid_acc': []}\n",
    "\n",
    "    # set up loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, 'min', patience=patience, factor=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model = None\n",
    "\n",
    "    # traning loop\n",
    "    print('Training Starts:')\n",
    "    num_total_steps = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels= inputs.to(device).unsqueeze(1), labels.to(device)\n",
    "            # print(\"inputs after unsqueeze:\\n\", inputs)\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            cur_train_loss = criterion(outputs, labels)\n",
    "            # backward\n",
    "            cur_train_loss.backward()\n",
    "            optimizer.step()  # optimizer update all model parameters\n",
    "            optimizer.zero_grad()  # set gradient to zero, avoid gradient accumulating\n",
    "            # loss\n",
    "            train_loss += cur_train_loss.item()\n",
    "            # acc\n",
    "            _, pred_class = torch.max(outputs, 1)\n",
    "            train_acc += (pred_class == labels).float().mean().item()\n",
    "\n",
    "        # valid\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_acc = 0\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs, labels= inputs.to(device).unsqueeze(1), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                cur_valid_loss = criterion(outputs, labels)\n",
    "                val_loss += cur_valid_loss.item()\n",
    "                _, pred_class = torch.max(outputs, 1)\n",
    "                val_acc += (pred_class == labels).float().mean().item()\n",
    "\n",
    "        # print & record\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "        val_loss = val_loss / len(valid_loader)\n",
    "        val_acc = val_acc / len(valid_loader)\n",
    "        print(f\"Epoch:{epoch + 1} / {epochs}, train loss:{train_loss:.5f}, train acc: {train_acc:.5f}, valid loss:{val_loss:.5f}, valid acc:{val_acc:.5f}\")\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['valid_loss'].append(val_loss)\n",
    "        history['valid_acc'].append(val_acc)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Check if current epoch's loss is less than the best observed loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()  # Save the best model\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "        else:\n",
    "            patience_counter += 1  # Increment patience counter\n",
    "\n",
    "        # Check if patience limit is reached\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    test_labels = []\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels= inputs.to(device).unsqueeze(1), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct = preds.eq(labels.view_as(preds))\n",
    "            total_correct += correct.sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    test_acc = total_correct / total_samples\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(classification_report(test_labels, test_preds))\n",
    "\n",
    "    return test_acc, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c397c333ffac432b825d26c36a6ab4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "features:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: mfcc/contrast\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.93473, train acc: 0.46787, valid loss:1.59389, valid acc:0.55104\n",
      "Epoch:2 / 200, train loss:1.58137, train acc: 0.54273, valid loss:1.40854, valid acc:0.59401\n",
      "Epoch:3 / 200, train loss:1.45455, train acc: 0.57400, valid loss:1.32250, valid acc:0.61749\n",
      "Epoch:4 / 200, train loss:1.38207, train acc: 0.59385, valid loss:1.28598, valid acc:0.62643\n",
      "Epoch:5 / 200, train loss:1.33097, train acc: 0.60756, valid loss:1.26032, valid acc:0.62565\n",
      "Epoch:6 / 200, train loss:1.29437, train acc: 0.61438, valid loss:1.23256, valid acc:0.63893\n",
      "Epoch:7 / 200, train loss:1.26354, train acc: 0.62123, valid loss:1.21880, valid acc:0.63859\n",
      "Epoch:8 / 200, train loss:1.23440, train acc: 0.63094, valid loss:1.20381, valid acc:0.65030\n",
      "Epoch:9 / 200, train loss:1.21349, train acc: 0.63710, valid loss:1.19072, valid acc:0.64835\n",
      "Epoch:10 / 200, train loss:1.19556, train acc: 0.63535, valid loss:1.18873, valid acc:0.64640\n",
      "Epoch:11 / 200, train loss:1.17363, train acc: 0.64548, valid loss:1.17459, valid acc:0.64757\n",
      "Epoch:12 / 200, train loss:1.15594, train acc: 0.64812, valid loss:1.17544, valid acc:0.65148\n",
      "Epoch:13 / 200, train loss:1.14531, train acc: 0.64735, valid loss:1.16717, valid acc:0.65734\n",
      "Epoch:14 / 200, train loss:1.12612, train acc: 0.65266, valid loss:1.15910, valid acc:0.66480\n",
      "Epoch:15 / 200, train loss:1.11869, train acc: 0.65608, valid loss:1.17549, valid acc:0.65421\n",
      "Epoch:16 / 200, train loss:1.09627, train acc: 0.66468, valid loss:1.15723, valid acc:0.65855\n",
      "Epoch:17 / 200, train loss:1.08524, train acc: 0.66768, valid loss:1.15281, valid acc:0.65382\n",
      "Epoch:18 / 200, train loss:1.07746, train acc: 0.66959, valid loss:1.16171, valid acc:0.65499\n",
      "Epoch:19 / 200, train loss:1.07049, train acc: 0.67157, valid loss:1.15533, valid acc:0.65304\n",
      "Epoch:20 / 200, train loss:1.05223, train acc: 0.67601, valid loss:1.14725, valid acc:0.65616\n",
      "Epoch:21 / 200, train loss:1.04568, train acc: 0.67469, valid loss:1.14549, valid acc:0.66163\n",
      "Epoch:22 / 200, train loss:1.03166, train acc: 0.68105, valid loss:1.16096, valid acc:0.64957\n",
      "Epoch:23 / 200, train loss:1.02763, train acc: 0.68252, valid loss:1.14709, valid acc:0.66207\n",
      "Epoch:24 / 200, train loss:1.01667, train acc: 0.68595, valid loss:1.14531, valid acc:0.66007\n",
      "Epoch:25 / 200, train loss:1.00446, train acc: 0.68916, valid loss:1.15011, valid acc:0.65812\n",
      "Epoch:26 / 200, train loss:0.99982, train acc: 0.69097, valid loss:1.15036, valid acc:0.65425\n",
      "Epoch:27 / 200, train loss:0.98996, train acc: 0.68851, valid loss:1.16274, valid acc:0.65347\n",
      "Epoch:28 / 200, train loss:0.98183, train acc: 0.69732, valid loss:1.15585, valid acc:0.65538\n",
      "Epoch:29 / 200, train loss:0.97501, train acc: 0.69565, valid loss:1.15595, valid acc:0.65929\n",
      "Epoch:30 / 200, train loss:0.96920, train acc: 0.69801, valid loss:1.15203, valid acc:0.65030\n",
      "Epoch:31 / 200, train loss:0.94109, train acc: 0.70796, valid loss:1.14947, valid acc:0.65616\n",
      "Epoch:32 / 200, train loss:0.93210, train acc: 0.71005, valid loss:1.15187, valid acc:0.65734\n",
      "Epoch:33 / 200, train loss:0.92911, train acc: 0.71270, valid loss:1.15027, valid acc:0.65812\n",
      "Epoch:34 / 200, train loss:0.92730, train acc: 0.71305, valid loss:1.15097, valid acc:0.65773\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.74      0.81      0.77        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.66      0.84      0.74       632\n",
      "           5       0.37      0.28      0.32       225\n",
      "           6       0.33      0.34      0.34       152\n",
      "           7       0.66      0.64      0.65       220\n",
      "           8       0.42      0.26      0.32       174\n",
      "           9       0.49      0.33      0.40       102\n",
      "          10       0.84      0.41      0.55        39\n",
      "          11       0.88      0.98      0.93        51\n",
      "          12       0.20      0.03      0.06       119\n",
      "          13       0.70      0.88      0.78       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.62      2573\n",
      "   macro avg       0.39      0.36      0.37      2573\n",
      "weighted avg       0.57      0.62      0.59      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.88428, train acc: 0.48192, valid loss:1.57999, valid acc:0.55781\n",
      "Epoch:2 / 200, train loss:1.55460, train acc: 0.54595, valid loss:1.41096, valid acc:0.59219\n",
      "Epoch:3 / 200, train loss:1.43383, train acc: 0.58125, valid loss:1.32784, valid acc:0.60273\n",
      "Epoch:4 / 200, train loss:1.35947, train acc: 0.60045, valid loss:1.28463, valid acc:0.62461\n",
      "Epoch:5 / 200, train loss:1.30867, train acc: 0.61364, valid loss:1.25565, valid acc:0.64180\n",
      "Epoch:6 / 200, train loss:1.26927, train acc: 0.62684, valid loss:1.23806, valid acc:0.63516\n",
      "Epoch:7 / 200, train loss:1.23893, train acc: 0.63000, valid loss:1.21060, valid acc:0.64375\n",
      "Epoch:8 / 200, train loss:1.21286, train acc: 0.63813, valid loss:1.19969, valid acc:0.64648\n",
      "Epoch:9 / 200, train loss:1.18928, train acc: 0.64514, valid loss:1.18569, valid acc:0.65391\n",
      "Epoch:10 / 200, train loss:1.16816, train acc: 0.64936, valid loss:1.17571, valid acc:0.65703\n",
      "Epoch:11 / 200, train loss:1.15623, train acc: 0.65169, valid loss:1.17707, valid acc:0.65547\n",
      "Epoch:12 / 200, train loss:1.13610, train acc: 0.65904, valid loss:1.17396, valid acc:0.65664\n",
      "Epoch:13 / 200, train loss:1.12098, train acc: 0.65926, valid loss:1.15954, valid acc:0.65078\n",
      "Epoch:14 / 200, train loss:1.10110, train acc: 0.66303, valid loss:1.16979, valid acc:0.65469\n",
      "Epoch:15 / 200, train loss:1.09135, train acc: 0.66723, valid loss:1.15025, valid acc:0.66055\n",
      "Epoch:16 / 200, train loss:1.07751, train acc: 0.67213, valid loss:1.15757, valid acc:0.65703\n",
      "Epoch:17 / 200, train loss:1.06839, train acc: 0.67201, valid loss:1.14953, valid acc:0.66328\n",
      "Epoch:18 / 200, train loss:1.05286, train acc: 0.67656, valid loss:1.14893, valid acc:0.66016\n",
      "Epoch:19 / 200, train loss:1.04281, train acc: 0.68160, valid loss:1.15200, valid acc:0.65938\n",
      "Epoch:20 / 200, train loss:1.03110, train acc: 0.68174, valid loss:1.15785, valid acc:0.65977\n",
      "Epoch:21 / 200, train loss:1.01683, train acc: 0.68904, valid loss:1.16007, valid acc:0.64410\n",
      "Epoch:22 / 200, train loss:1.01563, train acc: 0.68432, valid loss:1.15199, valid acc:0.65703\n",
      "Epoch:23 / 200, train loss:1.00182, train acc: 0.69121, valid loss:1.14496, valid acc:0.65938\n",
      "Epoch:24 / 200, train loss:0.99508, train acc: 0.69327, valid loss:1.15558, valid acc:0.65312\n",
      "Epoch:25 / 200, train loss:0.98313, train acc: 0.69645, valid loss:1.14645, valid acc:0.66016\n",
      "Epoch:26 / 200, train loss:0.97237, train acc: 0.70138, valid loss:1.15517, valid acc:0.65352\n",
      "Epoch:27 / 200, train loss:0.96899, train acc: 0.69767, valid loss:1.14966, valid acc:0.65078\n",
      "Epoch:28 / 200, train loss:0.96385, train acc: 0.70056, valid loss:1.15515, valid acc:0.65234\n",
      "Epoch:29 / 200, train loss:0.95246, train acc: 0.70604, valid loss:1.14676, valid acc:0.65508\n",
      "Epoch:30 / 200, train loss:0.94310, train acc: 0.70955, valid loss:1.15198, valid acc:0.65586\n",
      "Epoch:31 / 200, train loss:0.91862, train acc: 0.71764, valid loss:1.14665, valid acc:0.65664\n",
      "Epoch:32 / 200, train loss:0.91032, train acc: 0.71528, valid loss:1.14651, valid acc:0.65625\n",
      "Epoch:33 / 200, train loss:0.90697, train acc: 0.72281, valid loss:1.14300, valid acc:0.65898\n",
      "Epoch:34 / 200, train loss:0.90383, train acc: 0.72552, valid loss:1.14558, valid acc:0.65586\n",
      "Epoch:35 / 200, train loss:0.90117, train acc: 0.72183, valid loss:1.14625, valid acc:0.65742\n",
      "Epoch:36 / 200, train loss:0.90139, train acc: 0.72249, valid loss:1.14474, valid acc:0.65781\n",
      "Epoch:37 / 200, train loss:0.89609, train acc: 0.72091, valid loss:1.14506, valid acc:0.65547\n",
      "Epoch:38 / 200, train loss:0.89272, train acc: 0.72813, valid loss:1.15236, valid acc:0.65586\n",
      "Epoch:39 / 200, train loss:0.89473, train acc: 0.72569, valid loss:1.14662, valid acc:0.65586\n",
      "Epoch:40 / 200, train loss:0.89046, train acc: 0.72428, valid loss:1.14850, valid acc:0.65391\n",
      "Epoch:41 / 200, train loss:0.88849, train acc: 0.72468, valid loss:1.14725, valid acc:0.65430\n",
      "Epoch:42 / 200, train loss:0.88857, train acc: 0.72823, valid loss:1.14888, valid acc:0.65586\n",
      "Epoch:43 / 200, train loss:0.88594, train acc: 0.72514, valid loss:1.14535, valid acc:0.65703\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.79      0.73      0.76        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.69      0.79      0.74       632\n",
      "           5       0.40      0.30      0.34       225\n",
      "           6       0.34      0.36      0.35       152\n",
      "           7       0.70      0.61      0.65       220\n",
      "           8       0.42      0.34      0.38       174\n",
      "           9       0.49      0.29      0.37       102\n",
      "          10       0.79      0.49      0.60        39\n",
      "          11       0.88      0.98      0.93        51\n",
      "          12       0.23      0.09      0.13       119\n",
      "          13       0.68      0.89      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.62      2573\n",
      "   macro avg       0.42      0.37      0.38      2573\n",
      "weighted avg       0.58      0.62      0.59      2573\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: mfcc/contrast/centroid\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.92390, train acc: 0.49106, valid loss:1.61269, valid acc:0.54870\n",
      "Epoch:2 / 200, train loss:1.56395, train acc: 0.56062, valid loss:1.41392, valid acc:0.58307\n",
      "Epoch:3 / 200, train loss:1.44078, train acc: 0.58614, valid loss:1.32862, valid acc:0.61745\n",
      "Epoch:4 / 200, train loss:1.36957, train acc: 0.60007, valid loss:1.28937, valid acc:0.62843\n",
      "Epoch:5 / 200, train loss:1.31927, train acc: 0.61171, valid loss:1.25299, valid acc:0.62218\n",
      "Epoch:6 / 200, train loss:1.28575, train acc: 0.61759, valid loss:1.24397, valid acc:0.62999\n",
      "Epoch:7 / 200, train loss:1.25253, train acc: 0.62834, valid loss:1.21645, valid acc:0.64332\n",
      "Epoch:8 / 200, train loss:1.22571, train acc: 0.63302, valid loss:1.21413, valid acc:0.64180\n",
      "Epoch:9 / 200, train loss:1.20639, train acc: 0.63758, valid loss:1.19982, valid acc:0.64214\n",
      "Epoch:10 / 200, train loss:1.18199, train acc: 0.64303, valid loss:1.19577, valid acc:0.64449\n",
      "Epoch:11 / 200, train loss:1.16729, train acc: 0.64730, valid loss:1.17851, valid acc:0.65586\n",
      "Epoch:12 / 200, train loss:1.15039, train acc: 0.65210, valid loss:1.18695, valid acc:0.63780\n",
      "Epoch:13 / 200, train loss:1.13463, train acc: 0.65814, valid loss:1.18643, valid acc:0.64410\n",
      "Epoch:14 / 200, train loss:1.11910, train acc: 0.65756, valid loss:1.18068, valid acc:0.64796\n",
      "Epoch:15 / 200, train loss:1.10785, train acc: 0.66234, valid loss:1.16974, valid acc:0.65469\n",
      "Epoch:16 / 200, train loss:1.09812, train acc: 0.66534, valid loss:1.17165, valid acc:0.64878\n",
      "Epoch:17 / 200, train loss:1.08220, train acc: 0.67184, valid loss:1.16788, valid acc:0.64718\n",
      "Epoch:18 / 200, train loss:1.07207, train acc: 0.67299, valid loss:1.16782, valid acc:0.64957\n",
      "Epoch:19 / 200, train loss:1.05799, train acc: 0.67454, valid loss:1.17297, valid acc:0.64171\n",
      "Epoch:20 / 200, train loss:1.04718, train acc: 0.67511, valid loss:1.17390, valid acc:0.64679\n",
      "Epoch:21 / 200, train loss:1.03785, train acc: 0.67895, valid loss:1.16495, valid acc:0.65386\n",
      "Epoch:22 / 200, train loss:1.03052, train acc: 0.68144, valid loss:1.16583, valid acc:0.64918\n",
      "Epoch:23 / 200, train loss:1.01795, train acc: 0.68540, valid loss:1.16887, valid acc:0.65543\n",
      "Epoch:24 / 200, train loss:1.01277, train acc: 0.68640, valid loss:1.16922, valid acc:0.64839\n",
      "Epoch:25 / 200, train loss:0.99880, train acc: 0.69111, valid loss:1.16703, valid acc:0.65582\n",
      "Epoch:26 / 200, train loss:0.99062, train acc: 0.69267, valid loss:1.16734, valid acc:0.64796\n",
      "Epoch:27 / 200, train loss:0.98955, train acc: 0.69279, valid loss:1.17187, valid acc:0.64913\n",
      "Epoch:28 / 200, train loss:0.97399, train acc: 0.69735, valid loss:1.17061, valid acc:0.65543\n",
      "Epoch:29 / 200, train loss:0.97070, train acc: 0.69753, valid loss:1.16897, valid acc:0.65816\n",
      "Epoch:30 / 200, train loss:0.96355, train acc: 0.70088, valid loss:1.17948, valid acc:0.64800\n",
      "Epoch:31 / 200, train loss:0.93366, train acc: 0.71355, valid loss:1.16846, valid acc:0.65464\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.80      0.76      0.78        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.66      0.82      0.73       632\n",
      "           5       0.39      0.34      0.36       225\n",
      "           6       0.28      0.23      0.25       152\n",
      "           7       0.65      0.59      0.62       220\n",
      "           8       0.44      0.23      0.30       174\n",
      "           9       0.49      0.37      0.42       102\n",
      "          10       0.94      0.38      0.55        39\n",
      "          11       0.84      0.96      0.90        51\n",
      "          12       0.35      0.06      0.10       119\n",
      "          13       0.67      0.89      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.62      2573\n",
      "   macro avg       0.41      0.35      0.36      2573\n",
      "weighted avg       0.57      0.62      0.58      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma/centroid\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.94161, train acc: 0.46920, valid loss:1.58308, valid acc:0.53937\n",
      "Epoch:2 / 200, train loss:1.55952, train acc: 0.53923, valid loss:1.41607, valid acc:0.57140\n",
      "Epoch:3 / 200, train loss:1.43788, train acc: 0.57659, valid loss:1.33379, valid acc:0.60977\n",
      "Epoch:4 / 200, train loss:1.36393, train acc: 0.59863, valid loss:1.29399, valid acc:0.61016\n",
      "Epoch:5 / 200, train loss:1.31341, train acc: 0.61319, valid loss:1.25727, valid acc:0.62539\n",
      "Epoch:6 / 200, train loss:1.27609, train acc: 0.62184, valid loss:1.22803, valid acc:0.63203\n",
      "Epoch:7 / 200, train loss:1.24521, train acc: 0.63179, valid loss:1.20481, valid acc:0.64453\n",
      "Epoch:8 / 200, train loss:1.21798, train acc: 0.63875, valid loss:1.20004, valid acc:0.64336\n",
      "Epoch:9 / 200, train loss:1.19216, train acc: 0.64324, valid loss:1.19465, valid acc:0.64609\n",
      "Epoch:10 / 200, train loss:1.17559, train acc: 0.64939, valid loss:1.17987, valid acc:0.65391\n",
      "Epoch:11 / 200, train loss:1.15244, train acc: 0.65256, valid loss:1.18078, valid acc:0.65000\n",
      "Epoch:12 / 200, train loss:1.13545, train acc: 0.65897, valid loss:1.17511, valid acc:0.64648\n",
      "Epoch:13 / 200, train loss:1.11880, train acc: 0.66110, valid loss:1.15894, valid acc:0.66055\n",
      "Epoch:14 / 200, train loss:1.10531, train acc: 0.66615, valid loss:1.15542, valid acc:0.65430\n",
      "Epoch:15 / 200, train loss:1.09544, train acc: 0.67011, valid loss:1.16191, valid acc:0.65039\n",
      "Epoch:16 / 200, train loss:1.07922, train acc: 0.67190, valid loss:1.15860, valid acc:0.65156\n",
      "Epoch:17 / 200, train loss:1.06619, train acc: 0.67637, valid loss:1.15801, valid acc:0.65898\n",
      "Epoch:18 / 200, train loss:1.05459, train acc: 0.67998, valid loss:1.15382, valid acc:0.65742\n",
      "Epoch:19 / 200, train loss:1.04217, train acc: 0.68428, valid loss:1.14430, valid acc:0.66211\n",
      "Epoch:20 / 200, train loss:1.03217, train acc: 0.68328, valid loss:1.14153, valid acc:0.66445\n",
      "Epoch:21 / 200, train loss:1.02472, train acc: 0.68647, valid loss:1.15405, valid acc:0.65625\n",
      "Epoch:22 / 200, train loss:1.01653, train acc: 0.69021, valid loss:1.15385, valid acc:0.65664\n",
      "Epoch:23 / 200, train loss:1.00365, train acc: 0.69348, valid loss:1.14953, valid acc:0.65977\n",
      "Epoch:24 / 200, train loss:0.99134, train acc: 0.69679, valid loss:1.15428, valid acc:0.65742\n",
      "Epoch:25 / 200, train loss:0.98715, train acc: 0.69793, valid loss:1.14759, valid acc:0.66484\n",
      "Epoch:26 / 200, train loss:0.97757, train acc: 0.70098, valid loss:1.14966, valid acc:0.65820\n",
      "Epoch:27 / 200, train loss:0.97044, train acc: 0.70176, valid loss:1.15041, valid acc:0.65781\n",
      "Epoch:28 / 200, train loss:0.95930, train acc: 0.70729, valid loss:1.15702, valid acc:0.65742\n",
      "Epoch:29 / 200, train loss:0.95640, train acc: 0.71072, valid loss:1.15184, valid acc:0.65742\n",
      "Epoch:30 / 200, train loss:0.94583, train acc: 0.70696, valid loss:1.15481, valid acc:0.65977\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.76      0.89      0.82        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.67      0.80      0.73       632\n",
      "           5       0.37      0.32      0.35       225\n",
      "           6       0.32      0.30      0.31       152\n",
      "           7       0.63      0.65      0.64       220\n",
      "           8       0.44      0.21      0.28       174\n",
      "           9       0.42      0.15      0.22       102\n",
      "          10       1.00      0.23      0.38        39\n",
      "          11       0.91      0.98      0.94        51\n",
      "          12       0.33      0.08      0.12       119\n",
      "          13       0.66      0.90      0.76       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.61      2573\n",
      "   macro avg       0.41      0.34      0.35      2573\n",
      "weighted avg       0.57      0.61      0.57      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma/centroid/tonnetz\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.95073, train acc: 0.46950, valid loss:1.61932, valid acc:0.54796\n",
      "Epoch:2 / 200, train loss:1.58692, train acc: 0.54576, valid loss:1.43695, valid acc:0.58633\n",
      "Epoch:3 / 200, train loss:1.45808, train acc: 0.57969, valid loss:1.36363, valid acc:0.60078\n",
      "Epoch:4 / 200, train loss:1.38279, train acc: 0.60151, valid loss:1.30189, valid acc:0.61562\n",
      "Epoch:5 / 200, train loss:1.32210, train acc: 0.61530, valid loss:1.26211, valid acc:0.62422\n",
      "Epoch:6 / 200, train loss:1.28255, train acc: 0.62573, valid loss:1.24077, valid acc:0.63906\n",
      "Epoch:7 / 200, train loss:1.25118, train acc: 0.63199, valid loss:1.20745, valid acc:0.65391\n",
      "Epoch:8 / 200, train loss:1.22082, train acc: 0.63990, valid loss:1.18793, valid acc:0.66172\n",
      "Epoch:9 / 200, train loss:1.19613, train acc: 0.64411, valid loss:1.19640, valid acc:0.65195\n",
      "Epoch:10 / 200, train loss:1.17202, train acc: 0.65138, valid loss:1.17067, valid acc:0.66250\n",
      "Epoch:11 / 200, train loss:1.14977, train acc: 0.65701, valid loss:1.17605, valid acc:0.65508\n",
      "Epoch:12 / 200, train loss:1.13678, train acc: 0.65989, valid loss:1.15975, valid acc:0.65859\n",
      "Epoch:13 / 200, train loss:1.11566, train acc: 0.66463, valid loss:1.15122, valid acc:0.66445\n",
      "Epoch:14 / 200, train loss:1.09798, train acc: 0.67013, valid loss:1.15331, valid acc:0.66172\n",
      "Epoch:15 / 200, train loss:1.08903, train acc: 0.67131, valid loss:1.15917, valid acc:0.66211\n",
      "Epoch:16 / 200, train loss:1.07386, train acc: 0.67454, valid loss:1.14849, valid acc:0.66758\n",
      "Epoch:17 / 200, train loss:1.05923, train acc: 0.68070, valid loss:1.14761, valid acc:0.66289\n",
      "Epoch:18 / 200, train loss:1.04812, train acc: 0.68260, valid loss:1.14047, valid acc:0.67266\n",
      "Epoch:19 / 200, train loss:1.03439, train acc: 0.68653, valid loss:1.13063, valid acc:0.67227\n",
      "Epoch:20 / 200, train loss:1.02368, train acc: 0.68895, valid loss:1.14088, valid acc:0.66328\n",
      "Epoch:21 / 200, train loss:1.01435, train acc: 0.69068, valid loss:1.13880, valid acc:0.66406\n",
      "Epoch:22 / 200, train loss:1.00286, train acc: 0.69145, valid loss:1.13825, valid acc:0.66211\n",
      "Epoch:23 / 200, train loss:0.99733, train acc: 0.69340, valid loss:1.13097, valid acc:0.67227\n",
      "Epoch:24 / 200, train loss:0.98577, train acc: 0.69863, valid loss:1.13215, valid acc:0.66719\n",
      "Epoch:25 / 200, train loss:0.98115, train acc: 0.69873, valid loss:1.12977, valid acc:0.66758\n",
      "Epoch:26 / 200, train loss:0.96748, train acc: 0.70065, valid loss:1.12737, valid acc:0.67031\n",
      "Epoch:27 / 200, train loss:0.95773, train acc: 0.70599, valid loss:1.13429, valid acc:0.66914\n",
      "Epoch:28 / 200, train loss:0.94665, train acc: 0.70986, valid loss:1.13877, valid acc:0.66445\n",
      "Epoch:29 / 200, train loss:0.94495, train acc: 0.71092, valid loss:1.13558, valid acc:0.67070\n",
      "Epoch:30 / 200, train loss:0.93539, train acc: 0.71123, valid loss:1.13767, valid acc:0.66758\n",
      "Epoch:31 / 200, train loss:0.90749, train acc: 0.72262, valid loss:1.13378, valid acc:0.67305\n",
      "Epoch:32 / 200, train loss:0.90103, train acc: 0.72261, valid loss:1.13015, valid acc:0.66953\n",
      "Epoch:33 / 200, train loss:0.89160, train acc: 0.72844, valid loss:1.12755, valid acc:0.67266\n",
      "Epoch:34 / 200, train loss:0.89179, train acc: 0.72725, valid loss:1.12738, valid acc:0.66992\n",
      "Epoch:35 / 200, train loss:0.88968, train acc: 0.72845, valid loss:1.12918, valid acc:0.66992\n",
      "Epoch:36 / 200, train loss:0.89160, train acc: 0.72677, valid loss:1.12991, valid acc:0.67227\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.83      0.81      0.82        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.67      0.82      0.74       632\n",
      "           5       0.39      0.36      0.38       225\n",
      "           6       0.31      0.38      0.34       152\n",
      "           7       0.68      0.61      0.64       220\n",
      "           8       0.47      0.24      0.31       174\n",
      "           9       0.55      0.25      0.35       102\n",
      "          10       0.82      0.36      0.50        39\n",
      "          11       0.93      0.98      0.95        51\n",
      "          12       0.29      0.04      0.07       119\n",
      "          13       0.69      0.88      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.62      2573\n",
      "   macro avg       0.41      0.36      0.37      2573\n",
      "weighted avg       0.58      0.62      0.59      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma/centroid/zcr\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.89267, train acc: 0.48786, valid loss:1.57676, valid acc:0.54757\n",
      "Epoch:2 / 200, train loss:1.54987, train acc: 0.54838, valid loss:1.42408, valid acc:0.58780\n",
      "Epoch:3 / 200, train loss:1.43619, train acc: 0.58226, valid loss:1.34417, valid acc:0.60304\n",
      "Epoch:4 / 200, train loss:1.36607, train acc: 0.60036, valid loss:1.28997, valid acc:0.62261\n",
      "Epoch:5 / 200, train loss:1.31551, train acc: 0.61679, valid loss:1.25604, valid acc:0.62925\n",
      "Epoch:6 / 200, train loss:1.27594, train acc: 0.62513, valid loss:1.23667, valid acc:0.63863\n",
      "Epoch:7 / 200, train loss:1.24509, train acc: 0.63074, valid loss:1.21895, valid acc:0.64488\n",
      "Epoch:8 / 200, train loss:1.21152, train acc: 0.63953, valid loss:1.21464, valid acc:0.63711\n",
      "Epoch:9 / 200, train loss:1.18780, train acc: 0.64496, valid loss:1.19591, valid acc:0.64918\n",
      "Epoch:10 / 200, train loss:1.16610, train acc: 0.65053, valid loss:1.18160, valid acc:0.64835\n",
      "Epoch:11 / 200, train loss:1.14424, train acc: 0.65555, valid loss:1.17815, valid acc:0.65898\n",
      "Epoch:12 / 200, train loss:1.12957, train acc: 0.66000, valid loss:1.18171, valid acc:0.64766\n",
      "Epoch:13 / 200, train loss:1.11665, train acc: 0.66166, valid loss:1.16893, valid acc:0.65660\n",
      "Epoch:14 / 200, train loss:1.09735, train acc: 0.66806, valid loss:1.16558, valid acc:0.65664\n",
      "Epoch:15 / 200, train loss:1.07938, train acc: 0.67239, valid loss:1.15496, valid acc:0.65938\n",
      "Epoch:16 / 200, train loss:1.06855, train acc: 0.67626, valid loss:1.15853, valid acc:0.65586\n",
      "Epoch:17 / 200, train loss:1.05796, train acc: 0.67699, valid loss:1.15316, valid acc:0.65117\n",
      "Epoch:18 / 200, train loss:1.04681, train acc: 0.67814, valid loss:1.15984, valid acc:0.65547\n",
      "Epoch:19 / 200, train loss:1.03672, train acc: 0.68272, valid loss:1.15560, valid acc:0.65972\n",
      "Epoch:20 / 200, train loss:1.02314, train acc: 0.68919, valid loss:1.15088, valid acc:0.66211\n",
      "Epoch:21 / 200, train loss:1.00863, train acc: 0.69339, valid loss:1.15051, valid acc:0.66328\n",
      "Epoch:22 / 200, train loss:1.00536, train acc: 0.68738, valid loss:1.14815, valid acc:0.66133\n",
      "Epoch:23 / 200, train loss:0.99153, train acc: 0.69517, valid loss:1.15101, valid acc:0.66016\n",
      "Epoch:24 / 200, train loss:0.98278, train acc: 0.69818, valid loss:1.14244, valid acc:0.66094\n",
      "Epoch:25 / 200, train loss:0.97293, train acc: 0.70091, valid loss:1.15107, valid acc:0.65347\n",
      "Epoch:26 / 200, train loss:0.96930, train acc: 0.70309, valid loss:1.14663, valid acc:0.65781\n",
      "Epoch:27 / 200, train loss:0.95493, train acc: 0.70727, valid loss:1.15176, valid acc:0.66016\n",
      "Epoch:28 / 200, train loss:0.94701, train acc: 0.70700, valid loss:1.15844, valid acc:0.65469\n",
      "Epoch:29 / 200, train loss:0.94068, train acc: 0.70983, valid loss:1.16163, valid acc:0.65391\n",
      "Epoch:30 / 200, train loss:0.93394, train acc: 0.71032, valid loss:1.15529, valid acc:0.65820\n",
      "Epoch:31 / 200, train loss:0.90524, train acc: 0.72154, valid loss:1.14823, valid acc:0.65820\n",
      "Epoch:32 / 200, train loss:0.89713, train acc: 0.72515, valid loss:1.14638, valid acc:0.65898\n",
      "Epoch:33 / 200, train loss:0.89121, train acc: 0.72305, valid loss:1.14604, valid acc:0.65781\n",
      "Epoch:34 / 200, train loss:0.89234, train acc: 0.72707, valid loss:1.14940, valid acc:0.65391\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.75      0.81      0.78        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.65      0.82      0.73       632\n",
      "           5       0.41      0.29      0.34       225\n",
      "           6       0.31      0.28      0.29       152\n",
      "           7       0.65      0.60      0.62       220\n",
      "           8       0.47      0.24      0.32       174\n",
      "           9       0.47      0.31      0.38       102\n",
      "          10       0.89      0.44      0.59        39\n",
      "          11       0.91      0.98      0.94        51\n",
      "          12       0.16      0.03      0.04       119\n",
      "          13       0.66      0.89      0.76       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.62      2573\n",
      "   macro avg       0.42      0.36      0.37      2573\n",
      "weighted avg       0.56      0.62      0.57      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: all_non-echonest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.94501, train acc: 0.44080, valid loss:1.64946, valid acc:0.53585\n",
      "Epoch:2 / 200, train loss:1.60883, train acc: 0.52545, valid loss:1.46972, valid acc:0.56871\n",
      "Epoch:3 / 200, train loss:1.48238, train acc: 0.56395, valid loss:1.39677, valid acc:0.59644\n",
      "Epoch:4 / 200, train loss:1.40169, train acc: 0.58960, valid loss:1.33786, valid acc:0.61324\n",
      "Epoch:5 / 200, train loss:1.35108, train acc: 0.60367, valid loss:1.30101, valid acc:0.62578\n",
      "Epoch:6 / 200, train loss:1.30890, train acc: 0.61404, valid loss:1.26503, valid acc:0.63398\n",
      "Epoch:7 / 200, train loss:1.27091, train acc: 0.62643, valid loss:1.23936, valid acc:0.64609\n",
      "Epoch:8 / 200, train loss:1.24000, train acc: 0.63209, valid loss:1.21757, valid acc:0.64727\n",
      "Epoch:9 / 200, train loss:1.21633, train acc: 0.63845, valid loss:1.21875, valid acc:0.65078\n",
      "Epoch:10 / 200, train loss:1.19244, train acc: 0.64311, valid loss:1.22013, valid acc:0.64414\n",
      "Epoch:11 / 200, train loss:1.17504, train acc: 0.64762, valid loss:1.20237, valid acc:0.65820\n",
      "Epoch:12 / 200, train loss:1.15527, train acc: 0.65298, valid loss:1.18913, valid acc:0.65781\n",
      "Epoch:13 / 200, train loss:1.13587, train acc: 0.65946, valid loss:1.18134, valid acc:0.66055\n",
      "Epoch:14 / 200, train loss:1.12158, train acc: 0.66195, valid loss:1.17101, valid acc:0.66523\n",
      "Epoch:15 / 200, train loss:1.10811, train acc: 0.66319, valid loss:1.17386, valid acc:0.66328\n",
      "Epoch:16 / 200, train loss:1.09420, train acc: 0.66883, valid loss:1.17441, valid acc:0.66406\n",
      "Epoch:17 / 200, train loss:1.08048, train acc: 0.67199, valid loss:1.16532, valid acc:0.66406\n",
      "Epoch:18 / 200, train loss:1.06863, train acc: 0.67627, valid loss:1.17721, valid acc:0.65781\n",
      "Epoch:19 / 200, train loss:1.05809, train acc: 0.67844, valid loss:1.16081, valid acc:0.66484\n",
      "Epoch:20 / 200, train loss:1.04972, train acc: 0.68317, valid loss:1.17020, valid acc:0.65977\n",
      "Epoch:21 / 200, train loss:1.03703, train acc: 0.68488, valid loss:1.15653, valid acc:0.66875\n",
      "Epoch:22 / 200, train loss:1.02922, train acc: 0.68716, valid loss:1.14582, valid acc:0.67148\n",
      "Epoch:23 / 200, train loss:1.01564, train acc: 0.68842, valid loss:1.15504, valid acc:0.66953\n",
      "Epoch:24 / 200, train loss:1.00770, train acc: 0.69435, valid loss:1.15735, valid acc:0.66484\n",
      "Epoch:25 / 200, train loss:1.00254, train acc: 0.69592, valid loss:1.14541, valid acc:0.67383\n",
      "Epoch:26 / 200, train loss:0.99190, train acc: 0.69417, valid loss:1.14190, valid acc:0.67266\n",
      "Epoch:27 / 200, train loss:0.98337, train acc: 0.70010, valid loss:1.14747, valid acc:0.67031\n",
      "Epoch:28 / 200, train loss:0.97299, train acc: 0.70138, valid loss:1.14558, valid acc:0.67266\n",
      "Epoch:29 / 200, train loss:0.96419, train acc: 0.70351, valid loss:1.14927, valid acc:0.66992\n",
      "Epoch:30 / 200, train loss:0.95261, train acc: 0.70892, valid loss:1.14310, valid acc:0.67812\n",
      "Epoch:31 / 200, train loss:0.93216, train acc: 0.71411, valid loss:1.14291, valid acc:0.67578\n",
      "Epoch:32 / 200, train loss:0.91983, train acc: 0.71715, valid loss:1.15232, valid acc:0.67539\n",
      "Epoch:33 / 200, train loss:0.92318, train acc: 0.71688, valid loss:1.13735, valid acc:0.67852\n",
      "Epoch:34 / 200, train loss:0.91648, train acc: 0.71912, valid loss:1.14058, valid acc:0.67734\n",
      "Epoch:35 / 200, train loss:0.91714, train acc: 0.72114, valid loss:1.13842, valid acc:0.68125\n",
      "Epoch:36 / 200, train loss:0.91179, train acc: 0.72220, valid loss:1.14109, valid acc:0.67812\n",
      "Epoch:37 / 200, train loss:0.90869, train acc: 0.72287, valid loss:1.14014, valid acc:0.68008\n",
      "Epoch:38 / 200, train loss:0.91007, train acc: 0.72066, valid loss:1.13923, valid acc:0.68047\n",
      "Epoch:39 / 200, train loss:0.91053, train acc: 0.72268, valid loss:1.13847, valid acc:0.68086\n",
      "Epoch:40 / 200, train loss:0.90465, train acc: 0.72221, valid loss:1.13823, valid acc:0.67930\n",
      "Epoch:41 / 200, train loss:0.90081, train acc: 0.72544, valid loss:1.14063, valid acc:0.67969\n",
      "Epoch:42 / 200, train loss:0.90073, train acc: 0.72705, valid loss:1.14086, valid acc:0.67812\n",
      "Epoch:43 / 200, train loss:0.89841, train acc: 0.72843, valid loss:1.13690, valid acc:0.68047\n",
      "Epoch:44 / 200, train loss:0.89736, train acc: 0.72595, valid loss:1.13673, valid acc:0.68125\n",
      "Epoch:45 / 200, train loss:0.89800, train acc: 0.72247, valid loss:1.13871, valid acc:0.68086\n",
      "Epoch:46 / 200, train loss:0.89694, train acc: 0.72868, valid loss:1.13692, valid acc:0.68203\n",
      "Epoch:47 / 200, train loss:0.89291, train acc: 0.72781, valid loss:1.13503, valid acc:0.68281\n",
      "Epoch:48 / 200, train loss:0.89175, train acc: 0.72888, valid loss:1.13467, valid acc:0.68203\n",
      "Epoch:49 / 200, train loss:0.89329, train acc: 0.72945, valid loss:1.13790, valid acc:0.68008\n",
      "Epoch:50 / 200, train loss:0.89080, train acc: 0.72653, valid loss:1.13698, valid acc:0.68164\n",
      "Epoch:51 / 200, train loss:0.88984, train acc: 0.72955, valid loss:1.13822, valid acc:0.68164\n",
      "Epoch:52 / 200, train loss:0.88773, train acc: 0.72710, valid loss:1.13587, valid acc:0.68086\n",
      "Epoch:53 / 200, train loss:0.89298, train acc: 0.72625, valid loss:1.13804, valid acc:0.68008\n",
      "Epoch:54 / 200, train loss:0.88218, train acc: 0.73069, valid loss:1.13651, valid acc:0.68242\n",
      "Epoch:55 / 200, train loss:0.88437, train acc: 0.72539, valid loss:1.13617, valid acc:0.68203\n",
      "Epoch:56 / 200, train loss:0.88564, train acc: 0.72908, valid loss:1.13815, valid acc:0.68086\n",
      "Epoch:57 / 200, train loss:0.88039, train acc: 0.73066, valid loss:1.16114, valid acc:0.67461\n",
      "Epoch:58 / 200, train loss:0.88269, train acc: 0.73045, valid loss:1.13790, valid acc:0.68203\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.81      0.82      0.82        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.64      0.85      0.73       632\n",
      "           5       0.37      0.36      0.36       225\n",
      "           6       0.31      0.32      0.32       152\n",
      "           7       0.72      0.58      0.64       220\n",
      "           8       0.48      0.25      0.33       174\n",
      "           9       0.51      0.28      0.36       102\n",
      "          10       0.78      0.46      0.58        39\n",
      "          11       0.93      0.98      0.95        51\n",
      "          12       0.32      0.11      0.16       119\n",
      "          13       0.71      0.86      0.78       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.63      2573\n",
      "   macro avg       0.43      0.37      0.39      2573\n",
      "weighted avg       0.59      0.63      0.59      2573\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_sets = {}\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "cnn_acc_sets = {}\n",
    "cnn_times = {}\n",
    "for fset_name, fset in tqdm(feature_sets.items(), desc='features'):\n",
    "    cnn_model = MusicGenreCNN(num_classes=16)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Feature set: {fset_name}\\n')\n",
    "    t = time.process_time()\n",
    "    test_acc_cnn, hist_cnn = train_model(cnn_model, tracks, features_all, fset, device,\n",
    "                                         multi_label=False, epochs=200, batch_size=64, patience = 10)\n",
    "    cnn_acc_sets[fset_name] = test_acc_cnn\n",
    "    cnn_times[fset_name] = time.process_time() - t\n",
    "    print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CNN model using different feature sets:\n",
      "Feature set\tAccuracy\n",
      "mfcc/contrast:\t0.6250\n",
      "mfcc/contrast/chroma:\t0.6238\n",
      "mfcc/contrast/centroid:\t0.6183\n",
      "mfcc/contrast/chroma/centroid:\t0.6137\n",
      "mfcc/contrast/chroma/centroid/tonnetz:\t0.6242\n",
      "mfcc/contrast/chroma/centroid/zcr:\t0.6168\n",
      "all_non-echonest:\t0.6269\n",
      "Training time of CNN model using different feature sets:\n",
      "Feature set\tTime\n",
      "mfcc/contrast:\t31.7812s\n",
      "mfcc/contrast/chroma:\t46.0938s\n",
      "mfcc/contrast/centroid:\t27.9375s\n",
      "mfcc/contrast/chroma/centroid:\t30.0469s\n",
      "mfcc/contrast/chroma/centroid/tonnetz:\t39.2344s\n",
      "mfcc/contrast/chroma/centroid/zcr:\t37.0312s\n",
      "all_non-echonest:\t45.4844s\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of CNN model using different feature sets:\\nFeature set\\tAccuracy')\n",
    "for name in list(cnn_acc_sets.keys()):\n",
    "    print(f'{name}:\\t{cnn_acc_sets[name]:.4f}')\n",
    "print('Training time of CNN model using different feature sets:\\nFeature set\\tTime')\n",
    "for name in list(cnn_times.keys()):\n",
    "    print(f'{name}:\\t{cnn_times[name]:.4f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGenreRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, bidirectional=False, dropout=0.5):\n",
    "        super(MusicGenreRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=input_size, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True, \n",
    "                            dropout=dropout if num_layers > 1 else 0, \n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        multiplier = 2 if bidirectional else 1\n",
    "        self.fc = nn.Linear(hidden_size * multiplier, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers * (2 if self.bidirectional else 1), x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * (2 if self.bidirectional else 1), x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19922,) (2505,) (2573,) (19922, 273) (2505, 273) (2573, 273)\n",
      "273\n"
     ]
    }
   ],
   "source": [
    "y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, ['mfcc', 'spectral_contrast', 'chroma_cens'], multi_label=False)\n",
    "print(y_train.shape, y_val.shape, y_test.shape, X_train.shape, X_val.shape, X_test.shape)\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3529dd3d04944c5dad4479060ad6e2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "features:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: mfcc/contrast\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.42500, train acc: 0.56262, valid loss:1.20225, valid acc:0.64058\n",
      "Epoch:2 / 200, train loss:1.15608, train acc: 0.63987, valid loss:1.16403, valid acc:0.64766\n",
      "Epoch:3 / 200, train loss:1.05324, train acc: 0.66938, valid loss:1.20464, valid acc:0.65464\n",
      "Epoch:4 / 200, train loss:0.97505, train acc: 0.69137, valid loss:1.14285, valid acc:0.66636\n",
      "Epoch:5 / 200, train loss:0.88638, train acc: 0.71818, valid loss:1.20844, valid acc:0.65777\n",
      "Epoch:6 / 200, train loss:0.80797, train acc: 0.74035, valid loss:1.21449, valid acc:0.65855\n",
      "Epoch:7 / 200, train loss:0.73338, train acc: 0.76155, valid loss:1.29924, valid acc:0.64362\n",
      "Epoch:8 / 200, train loss:0.66036, train acc: 0.78670, valid loss:1.34990, valid acc:0.62643\n",
      "Epoch:9 / 200, train loss:0.59129, train acc: 0.80784, valid loss:1.41046, valid acc:0.63273\n",
      "Epoch:10 / 200, train loss:0.52805, train acc: 0.82816, valid loss:1.48801, valid acc:0.63307\n",
      "Epoch:11 / 200, train loss:0.46924, train acc: 0.84554, valid loss:1.57843, valid acc:0.64727\n",
      "Epoch:12 / 200, train loss:0.42091, train acc: 0.86184, valid loss:1.63323, valid acc:0.64332\n",
      "Epoch:13 / 200, train loss:0.37714, train acc: 0.87552, valid loss:1.61179, valid acc:0.63160\n",
      "Epoch:14 / 200, train loss:0.32976, train acc: 0.89083, valid loss:1.80631, valid acc:0.61237\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.72      0.89      0.80        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.70      0.75      0.72       632\n",
      "           5       0.36      0.38      0.37       225\n",
      "           6       0.28      0.28      0.28       152\n",
      "           7       0.65      0.74      0.69       220\n",
      "           8       0.41      0.26      0.32       174\n",
      "           9       0.49      0.37      0.42       102\n",
      "          10       0.53      0.41      0.46        39\n",
      "          11       0.94      0.98      0.96        51\n",
      "          12       0.17      0.17      0.17       119\n",
      "          13       0.72      0.78      0.75       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.25      0.08      0.12        12\n",
      "\n",
      "    accuracy                           0.60      2573\n",
      "   macro avg       0.39      0.38      0.38      2573\n",
      "weighted avg       0.57      0.60      0.59      2573\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: mfcc/contrast/chroma\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.40808, train acc: 0.56764, valid loss:1.18564, valid acc:0.64918\n",
      "Epoch:2 / 200, train loss:1.12196, train acc: 0.65492, valid loss:1.14865, valid acc:0.66871\n",
      "Epoch:3 / 200, train loss:1.00324, train acc: 0.68451, valid loss:1.20758, valid acc:0.64844\n",
      "Epoch:4 / 200, train loss:0.89861, train acc: 0.71511, valid loss:1.20066, valid acc:0.64766\n",
      "Epoch:5 / 200, train loss:0.79146, train acc: 0.74719, valid loss:1.19959, valid acc:0.65191\n",
      "Epoch:6 / 200, train loss:0.69634, train acc: 0.77906, valid loss:1.28788, valid acc:0.64722\n",
      "Epoch:7 / 200, train loss:0.60369, train acc: 0.80906, valid loss:1.36834, valid acc:0.63984\n",
      "Epoch:8 / 200, train loss:0.51696, train acc: 0.83556, valid loss:1.39854, valid acc:0.65039\n",
      "Epoch:9 / 200, train loss:0.44503, train acc: 0.85719, valid loss:1.47855, valid acc:0.63828\n",
      "Epoch:10 / 200, train loss:0.37820, train acc: 0.87655, valid loss:1.58882, valid acc:0.63546\n",
      "Epoch:11 / 200, train loss:0.32741, train acc: 0.89203, valid loss:1.67841, valid acc:0.64019\n",
      "Epoch:12 / 200, train loss:0.28212, train acc: 0.90822, valid loss:1.79669, valid acc:0.63789\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.71      0.76      0.73        62\n",
      "           2       0.14      0.06      0.08        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.65      0.81      0.72       632\n",
      "           5       0.36      0.34      0.35       225\n",
      "           6       0.26      0.22      0.24       152\n",
      "           7       0.72      0.63      0.67       220\n",
      "           8       0.42      0.24      0.31       174\n",
      "           9       0.53      0.34      0.42       102\n",
      "          10       0.44      0.44      0.44        39\n",
      "          11       0.77      0.98      0.86        51\n",
      "          12       0.15      0.12      0.13       119\n",
      "          13       0.72      0.82      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.25      0.17      0.20        12\n",
      "\n",
      "    accuracy                           0.60      2573\n",
      "   macro avg       0.38      0.37      0.37      2573\n",
      "weighted avg       0.57      0.60      0.58      2573\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: mfcc/contrast/centroid\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.42834, train acc: 0.56262, valid loss:1.21205, valid acc:0.64570\n",
      "Epoch:2 / 200, train loss:1.15742, train acc: 0.63733, valid loss:1.17020, valid acc:0.65820\n",
      "Epoch:3 / 200, train loss:1.04945, train acc: 0.67006, valid loss:1.23486, valid acc:0.62604\n",
      "Epoch:4 / 200, train loss:0.96342, train acc: 0.69409, valid loss:1.19220, valid acc:0.64136\n",
      "Epoch:5 / 200, train loss:0.88008, train acc: 0.71685, valid loss:1.20554, valid acc:0.64996\n",
      "Epoch:6 / 200, train loss:0.79509, train acc: 0.74360, valid loss:1.25167, valid acc:0.65113\n",
      "Epoch:7 / 200, train loss:0.72390, train acc: 0.76667, valid loss:1.26876, valid acc:0.64913\n",
      "Epoch:8 / 200, train loss:0.64328, train acc: 0.79040, valid loss:1.33481, valid acc:0.64410\n",
      "Epoch:9 / 200, train loss:0.58980, train acc: 0.80919, valid loss:1.40337, valid acc:0.65308\n",
      "Epoch:10 / 200, train loss:0.51464, train acc: 0.83265, valid loss:1.55639, valid acc:0.60964\n",
      "Epoch:11 / 200, train loss:0.46159, train acc: 0.85068, valid loss:1.51442, valid acc:0.65699\n",
      "Epoch:12 / 200, train loss:0.40520, train acc: 0.86723, valid loss:1.63568, valid acc:0.63898\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.70      0.81      0.75        62\n",
      "           2       0.16      0.17      0.16        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.71      0.75      0.73       632\n",
      "           5       0.32      0.36      0.34       225\n",
      "           6       0.29      0.26      0.27       152\n",
      "           7       0.72      0.70      0.71       220\n",
      "           8       0.40      0.32      0.35       174\n",
      "           9       0.49      0.40      0.44       102\n",
      "          10       0.53      0.44      0.48        39\n",
      "          11       0.89      0.96      0.92        51\n",
      "          12       0.23      0.13      0.16       119\n",
      "          13       0.72      0.83      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.43      0.50      0.46        12\n",
      "\n",
      "    accuracy                           0.61      2573\n",
      "   macro avg       0.41      0.41      0.41      2573\n",
      "weighted avg       0.58      0.61      0.59      2573\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: mfcc/contrast/chroma/centroid\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.40065, train acc: 0.57030, valid loss:1.23331, valid acc:0.62183\n",
      "Epoch:2 / 200, train loss:1.11810, train acc: 0.65336, valid loss:1.17876, valid acc:0.63624\n",
      "Epoch:3 / 200, train loss:0.99719, train acc: 0.68924, valid loss:1.15177, valid acc:0.65312\n",
      "Epoch:4 / 200, train loss:0.89035, train acc: 0.71808, valid loss:1.16375, valid acc:0.65508\n",
      "Epoch:5 / 200, train loss:0.78870, train acc: 0.75017, valid loss:1.21039, valid acc:0.65699\n",
      "Epoch:6 / 200, train loss:0.68583, train acc: 0.78058, valid loss:1.24940, valid acc:0.64957\n",
      "Epoch:7 / 200, train loss:0.59265, train acc: 0.81159, valid loss:1.40140, valid acc:0.64336\n",
      "Epoch:8 / 200, train loss:0.51167, train acc: 0.83776, valid loss:1.41728, valid acc:0.64839\n",
      "Epoch:9 / 200, train loss:0.44384, train acc: 0.85826, valid loss:1.50820, valid acc:0.64453\n",
      "Epoch:10 / 200, train loss:0.38059, train acc: 0.87890, valid loss:1.57424, valid acc:0.63277\n",
      "Epoch:11 / 200, train loss:0.32401, train acc: 0.89515, valid loss:1.64847, valid acc:0.64488\n",
      "Epoch:12 / 200, train loss:0.28623, train acc: 0.90837, valid loss:1.70484, valid acc:0.63316\n",
      "Epoch:13 / 200, train loss:0.24919, train acc: 0.91861, valid loss:1.75448, valid acc:0.64019\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.66      0.89      0.76        62\n",
      "           2       0.12      0.06      0.08        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.71      0.78      0.74       632\n",
      "           5       0.35      0.37      0.36       225\n",
      "           6       0.26      0.20      0.23       152\n",
      "           7       0.73      0.67      0.70       220\n",
      "           8       0.44      0.40      0.42       174\n",
      "           9       0.52      0.40      0.45       102\n",
      "          10       0.58      0.49      0.53        39\n",
      "          11       0.94      0.96      0.95        51\n",
      "          12       0.24      0.18      0.20       119\n",
      "          13       0.74      0.82      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.47      0.67      0.55        12\n",
      "\n",
      "    accuracy                           0.62      2573\n",
      "   macro avg       0.42      0.43      0.42      2573\n",
      "weighted avg       0.59      0.62      0.60      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma/centroid/tonnetz\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.38756, train acc: 0.57492, valid loss:1.18243, valid acc:0.64062\n",
      "Epoch:2 / 200, train loss:1.10089, train acc: 0.65949, valid loss:1.14218, valid acc:0.66094\n",
      "Epoch:3 / 200, train loss:0.96903, train acc: 0.69710, valid loss:1.17177, valid acc:0.64835\n",
      "Epoch:4 / 200, train loss:0.85459, train acc: 0.73176, valid loss:1.18978, valid acc:0.65035\n",
      "Epoch:5 / 200, train loss:0.73810, train acc: 0.76739, valid loss:1.27768, valid acc:0.65425\n",
      "Epoch:6 / 200, train loss:0.63230, train acc: 0.80175, valid loss:1.29964, valid acc:0.65273\n",
      "Epoch:7 / 200, train loss:0.53263, train acc: 0.83032, valid loss:1.39083, valid acc:0.63780\n",
      "Epoch:8 / 200, train loss:0.45887, train acc: 0.85316, valid loss:1.50261, valid acc:0.63589\n",
      "Epoch:9 / 200, train loss:0.38940, train acc: 0.87399, valid loss:1.63687, valid acc:0.63945\n",
      "Epoch:10 / 200, train loss:0.32350, train acc: 0.89756, valid loss:1.69232, valid acc:0.62261\n",
      "Epoch:11 / 200, train loss:0.27399, train acc: 0.91218, valid loss:1.74359, valid acc:0.63980\n",
      "Epoch:12 / 200, train loss:0.24368, train acc: 0.92375, valid loss:1.86650, valid acc:0.63472\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.81      0.89      0.85        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.68      0.77      0.72       632\n",
      "           5       0.35      0.40      0.37       225\n",
      "           6       0.27      0.25      0.26       152\n",
      "           7       0.66      0.70      0.68       220\n",
      "           8       0.47      0.22      0.30       174\n",
      "           9       0.60      0.36      0.45       102\n",
      "          10       0.53      0.59      0.56        39\n",
      "          11       0.93      1.00      0.96        51\n",
      "          12       0.23      0.17      0.19       119\n",
      "          13       0.72      0.83      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.62      2573\n",
      "   macro avg       0.42      0.41      0.41      2573\n",
      "weighted avg       0.58      0.62      0.59      2573\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: mfcc/contrast/chroma/centroid/zcr\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.39676, train acc: 0.57310, valid loss:1.18431, valid acc:0.65195\n",
      "Epoch:2 / 200, train loss:1.11292, train acc: 0.65740, valid loss:1.13483, valid acc:0.65933\n",
      "Epoch:3 / 200, train loss:0.99337, train acc: 0.69094, valid loss:1.17789, valid acc:0.65273\n",
      "Epoch:4 / 200, train loss:0.88051, train acc: 0.72219, valid loss:1.22796, valid acc:0.64414\n",
      "Epoch:5 / 200, train loss:0.77821, train acc: 0.75384, valid loss:1.25039, valid acc:0.64332\n",
      "Epoch:6 / 200, train loss:0.67778, train acc: 0.78510, valid loss:1.29841, valid acc:0.64062\n",
      "Epoch:7 / 200, train loss:0.59095, train acc: 0.81326, valid loss:1.33922, valid acc:0.63941\n",
      "Epoch:8 / 200, train loss:0.50462, train acc: 0.84319, valid loss:1.38323, valid acc:0.64644\n",
      "Epoch:9 / 200, train loss:0.43335, train acc: 0.86164, valid loss:1.49518, valid acc:0.64527\n",
      "Epoch:10 / 200, train loss:0.36423, train acc: 0.88404, valid loss:1.65322, valid acc:0.64019\n",
      "Epoch:11 / 200, train loss:0.32321, train acc: 0.89673, valid loss:1.72927, valid acc:0.64023\n",
      "Epoch:12 / 200, train loss:0.27819, train acc: 0.91025, valid loss:1.87612, valid acc:0.63277\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.5962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.68      0.77      0.72        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.69      0.79      0.74       632\n",
      "           5       0.34      0.40      0.37       225\n",
      "           6       0.28      0.23      0.25       152\n",
      "           7       0.72      0.61      0.66       220\n",
      "           8       0.33      0.20      0.25       174\n",
      "           9       0.62      0.36      0.46       102\n",
      "          10       0.46      0.49      0.48        39\n",
      "          11       0.74      0.98      0.84        51\n",
      "          12       0.12      0.12      0.12       119\n",
      "          13       0.72      0.80      0.75       711\n",
      "          14       0.17      0.02      0.04        42\n",
      "          15       0.22      0.17      0.19        12\n",
      "\n",
      "    accuracy                           0.60      2573\n",
      "   macro avg       0.38      0.37      0.37      2573\n",
      "weighted avg       0.57      0.60      0.58      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: all_non-echonest\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.39928, train acc: 0.56879, valid loss:1.17401, valid acc:0.65156\n",
      "Epoch:2 / 200, train loss:1.09571, train acc: 0.66099, valid loss:1.19917, valid acc:0.63711\n",
      "Epoch:3 / 200, train loss:0.95739, train acc: 0.70452, valid loss:1.16577, valid acc:0.64996\n",
      "Epoch:4 / 200, train loss:0.83096, train acc: 0.74132, valid loss:1.23057, valid acc:0.63043\n",
      "Epoch:5 / 200, train loss:0.71411, train acc: 0.77773, valid loss:1.26998, valid acc:0.63976\n",
      "Epoch:6 / 200, train loss:0.60393, train acc: 0.81264, valid loss:1.35111, valid acc:0.63581\n",
      "Epoch:7 / 200, train loss:0.51808, train acc: 0.83700, valid loss:1.35035, valid acc:0.64323\n",
      "Epoch:8 / 200, train loss:0.43249, train acc: 0.86521, valid loss:1.47280, valid acc:0.63116\n",
      "Epoch:9 / 200, train loss:0.38330, train acc: 0.88148, valid loss:1.55017, valid acc:0.63424\n",
      "Epoch:10 / 200, train loss:0.32336, train acc: 0.89983, valid loss:1.57849, valid acc:0.62687\n",
      "Epoch:11 / 200, train loss:0.29258, train acc: 0.90702, valid loss:1.63840, valid acc:0.62960\n",
      "Epoch:12 / 200, train loss:0.26140, train acc: 0.91647, valid loss:1.75614, valid acc:0.63038\n",
      "Epoch:13 / 200, train loss:0.22163, train acc: 0.92771, valid loss:1.80799, valid acc:0.63976\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.69      0.82      0.75        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.69      0.77      0.73       632\n",
      "           5       0.40      0.40      0.40       225\n",
      "           6       0.24      0.30      0.27       152\n",
      "           7       0.78      0.66      0.72       220\n",
      "           8       0.33      0.19      0.24       174\n",
      "           9       0.44      0.29      0.35       102\n",
      "          10       0.67      0.36      0.47        39\n",
      "          11       0.96      0.96      0.96        51\n",
      "          12       0.18      0.18      0.18       119\n",
      "          13       0.72      0.83      0.77       711\n",
      "          14       0.25      0.02      0.04        42\n",
      "          15       0.50      0.17      0.25        12\n",
      "\n",
      "    accuracy                           0.61      2573\n",
      "   macro avg       0.43      0.37      0.38      2573\n",
      "weighted avg       0.59      0.61      0.59      2573\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "feature_sets = {}\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "rnn_acc_sets = {}\n",
    "rnn_times = {}\n",
    "for fset_name, fset in tqdm(feature_sets.items(), desc='features'):\n",
    "    y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label=False)\n",
    "    input_size = X_train.shape[1]\n",
    "    rnn_model = MusicGenreRNN(input_size, hidden_size=512, num_layers=4, num_classes=16, bidirectional=True, dropout=0.5)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Feature set: {fset_name}\\n')\n",
    "    t = time.process_time()\n",
    "    test_acc_rnn, hist_rnn = train_model(rnn_model, tracks, features_all, fset, device,\n",
    "                                         multi_label=False, epochs=200, batch_size=64, patience = 10)\n",
    "    rnn_acc_sets[fset_name] = test_acc_rnn\n",
    "    rnn_times[fset_name] = time.process_time() - t\n",
    "    print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RNN model using different feature sets:\n",
      "Feature set\tAccuracy\n",
      "mfcc/contrast:\t0.6012\n",
      "mfcc/contrast/chroma:\t0.6024\n",
      "mfcc/contrast/centroid:\t0.6102\n",
      "mfcc/contrast/chroma/centroid:\t0.6218\n",
      "mfcc/contrast/chroma/centroid/tonnetz:\t0.6156\n",
      "mfcc/contrast/chroma/centroid/zcr:\t0.5962\n",
      "all_non-echonest:\t0.6059\n",
      "Training time of RNN model using different feature sets:\n",
      "Feature set\tTime\n",
      "mfcc/contrast:\t20.9062s\n",
      "mfcc/contrast/chroma:\t22.3594s\n",
      "mfcc/contrast/centroid:\t22.8438s\n",
      "mfcc/contrast/chroma/centroid:\t25.0156s\n",
      "mfcc/contrast/chroma/centroid/tonnetz:\t23.2188s\n",
      "mfcc/contrast/chroma/centroid/zcr:\t18.3281s\n",
      "all_non-echonest:\t23.1875s\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of RNN model using different feature sets:\\nFeature set\\tAccuracy')\n",
    "for name in list(rnn_acc_sets.keys()):\n",
    "    print(f'{name}:\\t{rnn_acc_sets[name]:.4f}')\n",
    "print('Training time of RNN model using different feature sets:\\nFeature set\\tTime')\n",
    "for name in list(rnn_times.keys()):\n",
    "    print(f'{name}:\\t{rnn_times[name]:.4f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 CNN-RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGenreCNNRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MusicGenreCNNRNN, self).__init__()\n",
    "        # define CNN layers\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=512, \n",
    "            hidden_size=512,\n",
    "            num_layers=4,\n",
    "            batch_first=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.transpose(1, 2)  # (batch, seq, feature)\n",
    "        x, (h_n, c_n) = self.rnn(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5d09682a3d487589015a4df7cef3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "features:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: mfcc/contrast\n",
      "\n",
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.93068, train acc: 0.37908, valid loss:1.65315, valid acc:0.47444\n",
      "Epoch:2 / 200, train loss:1.60457, train acc: 0.49359, valid loss:1.42089, valid acc:0.56992\n",
      "Epoch:3 / 200, train loss:1.47978, train acc: 0.53316, valid loss:1.33280, valid acc:0.59171\n",
      "Epoch:4 / 200, train loss:1.40928, train acc: 0.55068, valid loss:1.30362, valid acc:0.60699\n",
      "Epoch:5 / 200, train loss:1.36588, train acc: 0.56712, valid loss:1.25399, valid acc:0.63160\n",
      "Epoch:6 / 200, train loss:1.31617, train acc: 0.58121, valid loss:1.26344, valid acc:0.61241\n",
      "Epoch:7 / 200, train loss:1.29147, train acc: 0.58927, valid loss:1.23863, valid acc:0.61910\n",
      "Epoch:8 / 200, train loss:1.25254, train acc: 0.59811, valid loss:1.25085, valid acc:0.62305\n",
      "Epoch:9 / 200, train loss:1.23067, train acc: 0.60490, valid loss:1.23420, valid acc:0.62773\n",
      "Epoch:10 / 200, train loss:1.20519, train acc: 0.61477, valid loss:1.24520, valid acc:0.62500\n",
      "Epoch:11 / 200, train loss:1.18173, train acc: 0.61900, valid loss:1.23452, valid acc:0.63438\n",
      "Epoch:12 / 200, train loss:1.15365, train acc: 0.62739, valid loss:1.22509, valid acc:0.63277\n",
      "Epoch:13 / 200, train loss:1.13505, train acc: 0.63467, valid loss:1.24260, valid acc:0.63711\n",
      "Epoch:14 / 200, train loss:1.11758, train acc: 0.63825, valid loss:1.22449, valid acc:0.62882\n",
      "Epoch:15 / 200, train loss:1.09206, train acc: 0.64671, valid loss:1.24054, valid acc:0.64019\n",
      "Epoch:16 / 200, train loss:1.07360, train acc: 0.65020, valid loss:1.25893, valid acc:0.63273\n",
      "Epoch:17 / 200, train loss:1.06072, train acc: 0.65362, valid loss:1.23327, valid acc:0.63711\n",
      "Epoch:18 / 200, train loss:1.03085, train acc: 0.66176, valid loss:1.26275, valid acc:0.63828\n",
      "Epoch:19 / 200, train loss:1.00828, train acc: 0.66968, valid loss:1.26023, valid acc:0.63125\n",
      "Epoch:20 / 200, train loss:0.98883, train acc: 0.67393, valid loss:1.26734, valid acc:0.62378\n",
      "Epoch:21 / 200, train loss:0.97613, train acc: 0.67659, valid loss:1.27560, valid acc:0.62305\n",
      "Epoch:22 / 200, train loss:0.95540, train acc: 0.68118, valid loss:1.28708, valid acc:0.62695\n",
      "Epoch:23 / 200, train loss:0.93115, train acc: 0.68899, valid loss:1.27875, valid acc:0.62378\n",
      "Epoch:24 / 200, train loss:0.90446, train acc: 0.70016, valid loss:1.28445, valid acc:0.62695\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.5869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.68      0.66      0.67        62\n",
      "           2       0.20      0.06      0.09        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.63      0.76      0.69       632\n",
      "           5       0.28      0.34      0.30       225\n",
      "           6       0.34      0.38      0.35       152\n",
      "           7       0.65      0.63      0.64       220\n",
      "           8       0.48      0.25      0.33       174\n",
      "           9       0.43      0.24      0.30       102\n",
      "          10       0.60      0.31      0.41        39\n",
      "          11       0.88      0.96      0.92        51\n",
      "          12       0.19      0.10      0.13       119\n",
      "          13       0.73      0.80      0.76       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.62      0.67      0.64        12\n",
      "\n",
      "    accuracy                           0.59      2573\n",
      "   macro avg       0.42      0.38      0.39      2573\n",
      "weighted avg       0.56      0.59      0.57      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:2.04443, train acc: 0.33113, valid loss:1.84159, valid acc:0.43937\n",
      "Epoch:2 / 200, train loss:1.76479, train acc: 0.44325, valid loss:1.59368, valid acc:0.51589\n",
      "Epoch:3 / 200, train loss:1.60605, train acc: 0.49102, valid loss:1.51902, valid acc:0.53503\n",
      "Epoch:4 / 200, train loss:1.51189, train acc: 0.51935, valid loss:1.43095, valid acc:0.54753\n",
      "Epoch:5 / 200, train loss:1.44026, train acc: 0.53777, valid loss:1.35849, valid acc:0.57105\n",
      "Epoch:6 / 200, train loss:1.39403, train acc: 0.55632, valid loss:1.34593, valid acc:0.57496\n",
      "Epoch:7 / 200, train loss:1.35087, train acc: 0.56553, valid loss:1.31726, valid acc:0.57565\n",
      "Epoch:8 / 200, train loss:1.31443, train acc: 0.57788, valid loss:1.27539, valid acc:0.60191\n",
      "Epoch:9 / 200, train loss:1.28519, train acc: 0.58905, valid loss:1.26194, valid acc:0.61211\n",
      "Epoch:10 / 200, train loss:1.25102, train acc: 0.60284, valid loss:1.29145, valid acc:0.60503\n",
      "Epoch:11 / 200, train loss:1.22625, train acc: 0.60743, valid loss:1.25298, valid acc:0.60890\n",
      "Epoch:12 / 200, train loss:1.20095, train acc: 0.61750, valid loss:1.27985, valid acc:0.60339\n",
      "Epoch:13 / 200, train loss:1.17396, train acc: 0.62127, valid loss:1.24575, valid acc:0.61510\n",
      "Epoch:14 / 200, train loss:1.15400, train acc: 0.62620, valid loss:1.25740, valid acc:0.62218\n",
      "Epoch:15 / 200, train loss:1.13205, train acc: 0.63605, valid loss:1.26101, valid acc:0.61667\n",
      "Epoch:16 / 200, train loss:1.11297, train acc: 0.64068, valid loss:1.23595, valid acc:0.62339\n",
      "Epoch:17 / 200, train loss:1.09420, train acc: 0.64484, valid loss:1.22802, valid acc:0.63043\n",
      "Epoch:18 / 200, train loss:1.07055, train acc: 0.65210, valid loss:1.25544, valid acc:0.62535\n",
      "Epoch:19 / 200, train loss:1.04678, train acc: 0.66001, valid loss:1.27166, valid acc:0.62769\n",
      "Epoch:20 / 200, train loss:1.03673, train acc: 0.66054, valid loss:1.24917, valid acc:0.63477\n",
      "Epoch:21 / 200, train loss:1.00467, train acc: 0.67236, valid loss:1.27223, valid acc:0.62457\n",
      "Epoch:22 / 200, train loss:0.98676, train acc: 0.67614, valid loss:1.24213, valid acc:0.64453\n",
      "Epoch:23 / 200, train loss:0.97652, train acc: 0.67909, valid loss:1.25425, valid acc:0.63477\n",
      "Epoch:24 / 200, train loss:0.95221, train acc: 0.68838, valid loss:1.25828, valid acc:0.63164\n",
      "Epoch:25 / 200, train loss:0.92317, train acc: 0.69850, valid loss:1.25611, valid acc:0.63824\n",
      "Epoch:26 / 200, train loss:0.90788, train acc: 0.70146, valid loss:1.31149, valid acc:0.62183\n",
      "Epoch:27 / 200, train loss:0.88609, train acc: 0.71296, valid loss:1.30667, valid acc:0.62769\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.5939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.64      0.77      0.70        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.65      0.73      0.69       632\n",
      "           5       0.32      0.24      0.27       225\n",
      "           6       0.37      0.34      0.35       152\n",
      "           7       0.68      0.63      0.65       220\n",
      "           8       0.49      0.32      0.39       174\n",
      "           9       0.46      0.29      0.36       102\n",
      "          10       0.38      0.23      0.29        39\n",
      "          11       0.91      0.96      0.93        51\n",
      "          12       0.16      0.10      0.12       119\n",
      "          13       0.66      0.87      0.75       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.40      0.17      0.24        12\n",
      "\n",
      "    accuracy                           0.59      2573\n",
      "   macro avg       0.38      0.35      0.36      2573\n",
      "weighted avg       0.55      0.59      0.56      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/centroid\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:1.95978, train acc: 0.38028, valid loss:1.57688, valid acc:0.51519\n",
      "Epoch:2 / 200, train loss:1.61044, train acc: 0.49130, valid loss:1.42371, valid acc:0.55069\n",
      "Epoch:3 / 200, train loss:1.49944, train acc: 0.52312, valid loss:1.37739, valid acc:0.57370\n",
      "Epoch:4 / 200, train loss:1.43880, train acc: 0.53999, valid loss:1.33133, valid acc:0.59054\n",
      "Epoch:5 / 200, train loss:1.38636, train acc: 0.55984, valid loss:1.33850, valid acc:0.59570\n",
      "Epoch:6 / 200, train loss:1.35132, train acc: 0.56976, valid loss:1.34968, valid acc:0.59640\n",
      "Epoch:7 / 200, train loss:1.31902, train acc: 0.58426, valid loss:1.27225, valid acc:0.61558\n",
      "Epoch:8 / 200, train loss:1.29227, train acc: 0.58539, valid loss:1.29672, valid acc:0.60577\n",
      "Epoch:9 / 200, train loss:1.25498, train acc: 0.59935, valid loss:1.28452, valid acc:0.61675\n",
      "Epoch:10 / 200, train loss:1.24023, train acc: 0.60465, valid loss:1.24087, valid acc:0.62813\n",
      "Epoch:11 / 200, train loss:1.22225, train acc: 0.61070, valid loss:1.28356, valid acc:0.63155\n",
      "Epoch:12 / 200, train loss:1.19616, train acc: 0.61742, valid loss:1.27077, valid acc:0.61914\n",
      "Epoch:13 / 200, train loss:1.16687, train acc: 0.62301, valid loss:1.24850, valid acc:0.63277\n",
      "Epoch:14 / 200, train loss:1.15061, train acc: 0.63051, valid loss:1.25793, valid acc:0.62500\n",
      "Epoch:15 / 200, train loss:1.13226, train acc: 0.63788, valid loss:1.26291, valid acc:0.61484\n",
      "Epoch:16 / 200, train loss:1.11314, train acc: 0.64091, valid loss:1.25085, valid acc:0.63672\n",
      "Epoch:17 / 200, train loss:1.09222, train acc: 0.64793, valid loss:1.29263, valid acc:0.61793\n",
      "Epoch:18 / 200, train loss:1.07673, train acc: 0.65205, valid loss:1.25701, valid acc:0.63594\n",
      "Epoch:19 / 200, train loss:1.05347, train acc: 0.66124, valid loss:1.28112, valid acc:0.62652\n",
      "Epoch:20 / 200, train loss:1.02769, train acc: 0.66605, valid loss:1.28454, valid acc:0.62652\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.5935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.54      0.50      0.52        62\n",
      "           2       0.05      0.06      0.05        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.68      0.75      0.71       632\n",
      "           5       0.30      0.23      0.26       225\n",
      "           6       0.28      0.28      0.28       152\n",
      "           7       0.63      0.65      0.64       220\n",
      "           8       0.39      0.30      0.34       174\n",
      "           9       0.44      0.37      0.40       102\n",
      "          10       0.67      0.31      0.42        39\n",
      "          11       0.87      0.94      0.91        51\n",
      "          12       0.15      0.06      0.08       119\n",
      "          13       0.70      0.87      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.38      0.50      0.43        12\n",
      "\n",
      "    accuracy                           0.59      2573\n",
      "   macro avg       0.38      0.36      0.36      2573\n",
      "weighted avg       0.55      0.59      0.57      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma/centroid\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:2.06453, train acc: 0.31944, valid loss:1.92677, valid acc:0.42448\n",
      "Epoch:2 / 200, train loss:1.81508, train acc: 0.42505, valid loss:1.71020, valid acc:0.47730\n",
      "Epoch:3 / 200, train loss:1.66442, train acc: 0.46319, valid loss:1.60322, valid acc:0.50543\n",
      "Epoch:4 / 200, train loss:1.57444, train acc: 0.49166, valid loss:1.55228, valid acc:0.50326\n",
      "Epoch:5 / 200, train loss:1.49838, train acc: 0.51382, valid loss:1.40160, valid acc:0.57886\n",
      "Epoch:6 / 200, train loss:1.42978, train acc: 0.54062, valid loss:1.36046, valid acc:0.57648\n",
      "Epoch:7 / 200, train loss:1.37747, train acc: 0.55726, valid loss:1.33675, valid acc:0.58194\n",
      "Epoch:8 / 200, train loss:1.32783, train acc: 0.57646, valid loss:1.30233, valid acc:0.59957\n",
      "Epoch:9 / 200, train loss:1.29558, train acc: 0.58304, valid loss:1.26685, valid acc:0.61007\n",
      "Epoch:10 / 200, train loss:1.26648, train acc: 0.59405, valid loss:1.30837, valid acc:0.60894\n",
      "Epoch:11 / 200, train loss:1.23831, train acc: 0.60195, valid loss:1.22247, valid acc:0.62027\n",
      "Epoch:12 / 200, train loss:1.21843, train acc: 0.60743, valid loss:1.24430, valid acc:0.62574\n",
      "Epoch:13 / 200, train loss:1.19434, train acc: 0.61654, valid loss:1.26083, valid acc:0.61910\n",
      "Epoch:14 / 200, train loss:1.16643, train acc: 0.62676, valid loss:1.23318, valid acc:0.63199\n",
      "Epoch:15 / 200, train loss:1.14166, train acc: 0.63475, valid loss:1.22903, valid acc:0.63698\n",
      "Epoch:16 / 200, train loss:1.12893, train acc: 0.63840, valid loss:1.23638, valid acc:0.63277\n",
      "Epoch:17 / 200, train loss:1.11234, train acc: 0.64020, valid loss:1.25367, valid acc:0.63077\n",
      "Epoch:18 / 200, train loss:1.08551, train acc: 0.64978, valid loss:1.23099, valid acc:0.62804\n",
      "Epoch:19 / 200, train loss:1.06486, train acc: 0.65392, valid loss:1.24128, valid acc:0.61662\n",
      "Epoch:20 / 200, train loss:1.03846, train acc: 0.66227, valid loss:1.32296, valid acc:0.61276\n",
      "Epoch:21 / 200, train loss:1.02946, train acc: 0.66079, valid loss:1.25569, valid acc:0.62999\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6090\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.57      0.69      0.62        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.66      0.76      0.71       632\n",
      "           5       0.29      0.33      0.31       225\n",
      "           6       0.37      0.38      0.38       152\n",
      "           7       0.66      0.62      0.64       220\n",
      "           8       0.46      0.37      0.41       174\n",
      "           9       0.47      0.23      0.30       102\n",
      "          10       0.47      0.38      0.42        39\n",
      "          11       0.91      0.98      0.94        51\n",
      "          12       0.32      0.09      0.14       119\n",
      "          13       0.73      0.85      0.79       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.62      0.42      0.50        12\n",
      "\n",
      "    accuracy                           0.61      2573\n",
      "   macro avg       0.41      0.38      0.39      2573\n",
      "weighted avg       0.57      0.61      0.58      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma/centroid/tonnetz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:2.06885, train acc: 0.31736, valid loss:1.90426, valid acc:0.43546\n",
      "Epoch:2 / 200, train loss:1.83099, train acc: 0.42014, valid loss:1.64533, valid acc:0.47448\n",
      "Epoch:3 / 200, train loss:1.64514, train acc: 0.46978, valid loss:1.49771, valid acc:0.52852\n",
      "Epoch:4 / 200, train loss:1.55899, train acc: 0.49460, valid loss:1.42725, valid acc:0.53589\n",
      "Epoch:5 / 200, train loss:1.49054, train acc: 0.51868, valid loss:1.40684, valid acc:0.54796\n",
      "Epoch:6 / 200, train loss:1.44648, train acc: 0.53435, valid loss:1.37695, valid acc:0.55308\n",
      "Epoch:7 / 200, train loss:1.40082, train acc: 0.54480, valid loss:1.33139, valid acc:0.58668\n",
      "Epoch:8 / 200, train loss:1.36717, train acc: 0.55898, valid loss:1.29230, valid acc:0.58863\n",
      "Epoch:9 / 200, train loss:1.33968, train acc: 0.56859, valid loss:1.30356, valid acc:0.58941\n",
      "Epoch:10 / 200, train loss:1.30771, train acc: 0.58183, valid loss:1.27043, valid acc:0.59449\n",
      "Epoch:11 / 200, train loss:1.27739, train acc: 0.58905, valid loss:1.24537, valid acc:0.60738\n",
      "Epoch:12 / 200, train loss:1.24997, train acc: 0.60014, valid loss:1.25092, valid acc:0.60430\n",
      "Epoch:13 / 200, train loss:1.23197, train acc: 0.60733, valid loss:1.25770, valid acc:0.60347\n",
      "Epoch:14 / 200, train loss:1.20316, train acc: 0.61279, valid loss:1.25963, valid acc:0.61406\n",
      "Epoch:15 / 200, train loss:1.18244, train acc: 0.61962, valid loss:1.22749, valid acc:0.62808\n",
      "Epoch:16 / 200, train loss:1.16334, train acc: 0.62515, valid loss:1.24211, valid acc:0.61992\n",
      "Epoch:17 / 200, train loss:1.13914, train acc: 0.63012, valid loss:1.23370, valid acc:0.61832\n",
      "Epoch:18 / 200, train loss:1.12742, train acc: 0.63477, valid loss:1.26722, valid acc:0.61246\n",
      "Epoch:19 / 200, train loss:1.10578, train acc: 0.64296, valid loss:1.22440, valid acc:0.63238\n",
      "Epoch:20 / 200, train loss:1.08033, train acc: 0.64992, valid loss:1.23589, valid acc:0.62808\n",
      "Epoch:21 / 200, train loss:1.06315, train acc: 0.65155, valid loss:1.24331, valid acc:0.62648\n",
      "Epoch:22 / 200, train loss:1.04520, train acc: 0.65794, valid loss:1.26366, valid acc:0.61832\n",
      "Epoch:23 / 200, train loss:1.01654, train acc: 0.66806, valid loss:1.27678, valid acc:0.61793\n",
      "Epoch:24 / 200, train loss:1.00467, train acc: 0.67014, valid loss:1.25218, valid acc:0.62969\n",
      "Epoch:25 / 200, train loss:0.97136, train acc: 0.68019, valid loss:1.24871, valid acc:0.63438\n",
      "Epoch:26 / 200, train loss:0.95338, train acc: 0.68644, valid loss:1.29648, valid acc:0.61710\n",
      "Epoch:27 / 200, train loss:0.93988, train acc: 0.68841, valid loss:1.29342, valid acc:0.61428\n",
      "Epoch:28 / 200, train loss:0.91585, train acc: 0.69460, valid loss:1.30670, valid acc:0.61241\n",
      "Epoch:29 / 200, train loss:0.88415, train acc: 0.70575, valid loss:1.29892, valid acc:0.61237\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.60      0.69      0.64        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.64      0.79      0.70       632\n",
      "           5       0.39      0.28      0.32       225\n",
      "           6       0.37      0.38      0.38       152\n",
      "           7       0.71      0.55      0.62       220\n",
      "           8       0.40      0.33      0.36       174\n",
      "           9       0.47      0.30      0.37       102\n",
      "          10       0.47      0.38      0.42        39\n",
      "          11       0.91      0.96      0.93        51\n",
      "          12       0.10      0.02      0.03       119\n",
      "          13       0.69      0.86      0.77       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.60      0.50      0.55        12\n",
      "\n",
      "    accuracy                           0.61      2573\n",
      "   macro avg       0.40      0.38      0.38      2573\n",
      "weighted avg       0.56      0.61      0.57      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: mfcc/contrast/chroma/centroid/zcr\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:2.01229, train acc: 0.34521, valid loss:1.81930, valid acc:0.39076\n",
      "Epoch:2 / 200, train loss:1.72028, train acc: 0.45360, valid loss:1.63000, valid acc:0.46311\n",
      "Epoch:3 / 200, train loss:1.59138, train acc: 0.48934, valid loss:1.50144, valid acc:0.52995\n",
      "Epoch:4 / 200, train loss:1.50521, train acc: 0.51615, valid loss:1.43990, valid acc:0.54288\n",
      "Epoch:5 / 200, train loss:1.43787, train acc: 0.53784, valid loss:1.36980, valid acc:0.56914\n",
      "Epoch:6 / 200, train loss:1.38671, train acc: 0.55726, valid loss:1.31201, valid acc:0.58511\n",
      "Epoch:7 / 200, train loss:1.35003, train acc: 0.56444, valid loss:1.33023, valid acc:0.58320\n",
      "Epoch:8 / 200, train loss:1.30934, train acc: 0.58053, valid loss:1.31289, valid acc:0.59288\n",
      "Epoch:9 / 200, train loss:1.26484, train acc: 0.59488, valid loss:1.25529, valid acc:0.60738\n",
      "Epoch:10 / 200, train loss:1.23463, train acc: 0.60628, valid loss:1.23032, valid acc:0.62144\n",
      "Epoch:11 / 200, train loss:1.21975, train acc: 0.60969, valid loss:1.26429, valid acc:0.59366\n",
      "Epoch:12 / 200, train loss:1.18783, train acc: 0.62105, valid loss:1.22144, valid acc:0.62617\n",
      "Epoch:13 / 200, train loss:1.17067, train acc: 0.62691, valid loss:1.23151, valid acc:0.62491\n",
      "Epoch:14 / 200, train loss:1.14217, train acc: 0.63533, valid loss:1.22913, valid acc:0.61523\n",
      "Epoch:15 / 200, train loss:1.12033, train acc: 0.63989, valid loss:1.23974, valid acc:0.61671\n",
      "Epoch:16 / 200, train loss:1.10202, train acc: 0.64559, valid loss:1.25480, valid acc:0.61319\n",
      "Epoch:17 / 200, train loss:1.08145, train acc: 0.65007, valid loss:1.22510, valid acc:0.61050\n",
      "Epoch:18 / 200, train loss:1.06583, train acc: 0.65628, valid loss:1.24457, valid acc:0.62808\n",
      "Epoch:19 / 200, train loss:1.04452, train acc: 0.66186, valid loss:1.23781, valid acc:0.63238\n",
      "Epoch:20 / 200, train loss:1.02421, train acc: 0.66839, valid loss:1.26407, valid acc:0.62296\n",
      "Epoch:21 / 200, train loss:0.99816, train acc: 0.67719, valid loss:1.27107, valid acc:0.61901\n",
      "Epoch:22 / 200, train loss:0.97946, train acc: 0.68311, valid loss:1.25646, valid acc:0.62695\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.5834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.62      0.52      0.56        62\n",
      "           2       0.20      0.06      0.09        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.59      0.76      0.66       632\n",
      "           5       0.26      0.36      0.30       225\n",
      "           6       0.31      0.40      0.35       152\n",
      "           7       0.73      0.54      0.62       220\n",
      "           8       0.44      0.23      0.30       174\n",
      "           9       0.47      0.31      0.38       102\n",
      "          10       0.50      0.46      0.48        39\n",
      "          11       0.93      0.98      0.95        51\n",
      "          12       0.28      0.07      0.11       119\n",
      "          13       0.77      0.81      0.79       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.44      0.58      0.50        12\n",
      "\n",
      "    accuracy                           0.58      2573\n",
      "   macro avg       0.41      0.38      0.38      2573\n",
      "weighted avg       0.57      0.58      0.56      2573\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Feature set: all_non-echonest\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts:\n",
      "Epoch:1 / 200, train loss:2.06749, train acc: 0.29595, valid loss:1.83568, valid acc:0.40807\n",
      "Epoch:2 / 200, train loss:1.70410, train acc: 0.45700, valid loss:1.55284, valid acc:0.50612\n",
      "Epoch:3 / 200, train loss:1.55741, train acc: 0.50256, valid loss:1.43437, valid acc:0.53924\n",
      "Epoch:4 / 200, train loss:1.48828, train acc: 0.52304, valid loss:1.41153, valid acc:0.55330\n",
      "Epoch:5 / 200, train loss:1.44393, train acc: 0.53762, valid loss:1.34206, valid acc:0.57951\n",
      "Epoch:6 / 200, train loss:1.40333, train acc: 0.54618, valid loss:1.33681, valid acc:0.58034\n",
      "Epoch:7 / 200, train loss:1.36485, train acc: 0.55747, valid loss:1.31822, valid acc:0.59605\n",
      "Epoch:8 / 200, train loss:1.33701, train acc: 0.56844, valid loss:1.29861, valid acc:0.59757\n",
      "Epoch:9 / 200, train loss:1.30370, train acc: 0.57833, valid loss:1.30570, valid acc:0.59839\n",
      "Epoch:10 / 200, train loss:1.29015, train acc: 0.58141, valid loss:1.27621, valid acc:0.60104\n",
      "Epoch:11 / 200, train loss:1.26062, train acc: 0.58945, valid loss:1.30338, valid acc:0.59679\n",
      "Epoch:12 / 200, train loss:1.24061, train acc: 0.59566, valid loss:1.31110, valid acc:0.60343\n",
      "Epoch:13 / 200, train loss:1.22169, train acc: 0.60387, valid loss:1.26533, valid acc:0.60972\n",
      "Epoch:14 / 200, train loss:1.19317, train acc: 0.61198, valid loss:1.24646, valid acc:0.61992\n",
      "Epoch:15 / 200, train loss:1.18080, train acc: 0.61307, valid loss:1.28896, valid acc:0.61007\n",
      "Epoch:16 / 200, train loss:1.16244, train acc: 0.61974, valid loss:1.24274, valid acc:0.61328\n",
      "Epoch:17 / 200, train loss:1.15100, train acc: 0.62446, valid loss:1.25416, valid acc:0.61714\n",
      "Epoch:18 / 200, train loss:1.12759, train acc: 0.63262, valid loss:1.27682, valid acc:0.61710\n",
      "Epoch:19 / 200, train loss:1.11518, train acc: 0.63599, valid loss:1.25651, valid acc:0.61554\n",
      "Epoch:20 / 200, train loss:1.08626, train acc: 0.64593, valid loss:1.25026, valid acc:0.62578\n",
      "Epoch:21 / 200, train loss:1.07296, train acc: 0.64779, valid loss:1.24150, valid acc:0.61597\n",
      "Epoch:22 / 200, train loss:1.05740, train acc: 0.65194, valid loss:1.21997, valid acc:0.62695\n",
      "Epoch:23 / 200, train loss:1.03813, train acc: 0.65558, valid loss:1.22863, valid acc:0.62808\n",
      "Epoch:24 / 200, train loss:1.02028, train acc: 0.66582, valid loss:1.23370, valid acc:0.62656\n",
      "Epoch:25 / 200, train loss:0.99837, train acc: 0.66993, valid loss:1.28511, valid acc:0.62305\n",
      "Epoch:26 / 200, train loss:0.98899, train acc: 0.67291, valid loss:1.26201, valid acc:0.64180\n",
      "Epoch:27 / 200, train loss:0.97383, train acc: 0.67886, valid loss:1.29780, valid acc:0.61719\n",
      "Epoch:28 / 200, train loss:0.95032, train acc: 0.68569, valid loss:1.29224, valid acc:0.62422\n",
      "Epoch:29 / 200, train loss:0.93704, train acc: 0.69084, valid loss:1.30414, valid acc:0.63281\n",
      "Epoch:30 / 200, train loss:0.91453, train acc: 0.69625, valid loss:1.30479, valid acc:0.63867\n",
      "Epoch:31 / 200, train loss:0.84215, train acc: 0.71901, valid loss:1.29002, valid acc:0.62969\n",
      "Epoch:32 / 200, train loss:0.80913, train acc: 0.72837, valid loss:1.28430, valid acc:0.63320\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.5966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.65      0.53      0.58        62\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.68      0.77      0.72       632\n",
      "           5       0.35      0.26      0.30       225\n",
      "           6       0.28      0.32      0.29       152\n",
      "           7       0.64      0.65      0.64       220\n",
      "           8       0.38      0.20      0.26       174\n",
      "           9       0.49      0.40      0.44       102\n",
      "          10       0.58      0.54      0.56        39\n",
      "          11       0.92      0.96      0.94        51\n",
      "          12       0.06      0.03      0.04       119\n",
      "          13       0.67      0.86      0.75       711\n",
      "          14       0.00      0.00      0.00        42\n",
      "          15       0.75      0.50      0.60        12\n",
      "\n",
      "    accuracy                           0.60      2573\n",
      "   macro avg       0.40      0.38      0.38      2573\n",
      "weighted avg       0.55      0.60      0.56      2573\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Cecilia\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_sets = {}\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "cnn_rnn_acc_sets = {}\n",
    "cnn_rnn_times = {}\n",
    "for fset_name, fset in tqdm(feature_sets.items(), desc='features'):\n",
    "    cnn_rnn_model = MusicGenreCNNRNN(num_classes=16)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Feature set: {fset_name}\\n')\n",
    "    t = time.process_time()\n",
    "    test_acc_cnn_rnn, hist_cnn_rnn = train_model(cnn_rnn_model, tracks, features_all, fset, device,\n",
    "                                         multi_label=False, epochs=200, batch_size=64, patience = 10)\n",
    "    cnn_rnn_acc_sets[fset_name] = test_acc_cnn_rnn\n",
    "    cnn_rnn_times[fset_name] = time.process_time() - t\n",
    "    print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CNN-RNN model using different feature sets:\n",
      "Feature set\tAccuracy\n",
      "mfcc/contrast:\t0.5869\n",
      "mfcc/contrast/chroma:\t0.5939\n",
      "mfcc/contrast/centroid:\t0.5935\n",
      "mfcc/contrast/chroma/centroid:\t0.6090\n",
      "mfcc/contrast/chroma/centroid/tonnetz:\t0.6055\n",
      "mfcc/contrast/chroma/centroid/zcr:\t0.5834\n",
      "all_non-echonest:\t0.5966\n",
      "Training time of CNN-RNN model using different feature sets:\n",
      "Feature set\tTime\n",
      "mfcc/contrast:\t63.2500s\n",
      "mfcc/contrast/chroma:\t52.6562s\n",
      "mfcc/contrast/centroid:\t53.3594s\n",
      "mfcc/contrast/chroma/centroid:\t41.5312s\n",
      "mfcc/contrast/chroma/centroid/tonnetz:\t57.7031s\n",
      "mfcc/contrast/chroma/centroid/zcr:\t41.6250s\n",
      "all_non-echonest:\t183.3594s\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of CNN-RNN model using different feature sets:\\nFeature set\\tAccuracy')\n",
    "for name in list(cnn_rnn_acc_sets.keys()):\n",
    "    print(f'{name}:\\t{cnn_rnn_acc_sets[name]:.4f}')\n",
    "print('Training time of CNN-RNN model using different feature sets:\\nFeature set\\tTime')\n",
    "for name in list(cnn_rnn_times.keys()):\n",
    "    print(f'{name}:\\t{cnn_rnn_times[name]:.4f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
